Found the following features in expression file:
left
base
right
processing: /home/ppp/Research_Projects/Merge_Conflicts/Resource/workspace/left/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java
processing: /home/ppp/Research_Projects/Merge_Conflicts/Resource/workspace/left/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java
processing: /home/ppp/Research_Projects/Merge_Conflicts/Resource/workspace/base/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java
processing: /home/ppp/Research_Projects/Merge_Conflicts/Resource/workspace/base/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java
processing: /home/ppp/Research_Projects/Merge_Conflicts/Resource/workspace/right/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java
processing: /home/ppp/Research_Projects/Merge_Conflicts/Resource/workspace/right/src/main/java/com/amazonaws/services/s3/transfer/TransferManager.java
[NT -> left : Feature]
	[NT -> src : Folder]
		[NT -> main : Folder]
			[NT -> java : Folder]
				[NT -> com : Folder]
					[NT -> amazonaws : Folder]
						[NT -> services : Folder]
							[NT -> s3 : Folder]
								[NT -> transfer : Folder]
									[NT -> TransferManager.java : Java-File]
										[NT -> - : CompilationUnit]
											[T -> - : PackageDeclaration "package com.amazonaws.services.s3.transfer;" compose:Replacement merge: Default]
											[T -> java.io.File{ImportPackage} : ImportDeclaration "import java.io.File;" compose:Replacement merge: Default]
											[T -> java.io.InputStream{ImportPackage} : ImportDeclaration "import java.io.InputStream;" compose:Replacement merge: Default]
											[T -> java.util.ArrayList{ImportPackage} : ImportDeclaration "import java.util.ArrayList;" compose:Replacement merge: Default]
											[T -> java.util.Date{ImportPackage} : ImportDeclaration "import java.util.Date;" compose:Replacement merge: Default]
											[T -> java.util.LinkedList{ImportPackage} : ImportDeclaration "import java.util.LinkedList;" compose:Replacement merge: Default]
											[T -> java.util.List{ImportPackage} : ImportDeclaration "import java.util.List;" compose:Replacement merge: Default]
											[T -> java.util.Stack{ImportPackage} : ImportDeclaration "import java.util.Stack;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.Callable{ImportPackage} : ImportDeclaration "import java.util.concurrent.Callable;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.Future{ImportPackage} : ImportDeclaration "import java.util.concurrent.Future;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ScheduledExecutorService{ImportPackage} : ImportDeclaration "import java.util.concurrent.ScheduledExecutorService;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ScheduledThreadPoolExecutor{ImportPackage} : ImportDeclaration "import java.util.concurrent.ScheduledThreadPoolExecutor;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ThreadPoolExecutor{ImportPackage} : ImportDeclaration "import java.util.concurrent.ThreadPoolExecutor;" compose:Replacement merge: Default]
											[T -> org.apache.commons.logging.Log{ImportPackage} : ImportDeclaration "import org.apache.commons.logging.Log;" compose:Replacement merge: Default]
											[T -> org.apache.commons.logging.LogFactory{ImportPackage} : ImportDeclaration "import org.apache.commons.logging.LogFactory;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonClientException{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonClientException;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonServiceException{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonServiceException;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonWebServiceRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonWebServiceRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.auth.AWSCredentials{ImportPackage} : ImportDeclaration "import com.amazonaws.auth.AWSCredentials;" compose:Replacement merge: Default]
											[T -> com.amazonaws.event.ProgressListener{ImportPackage} : ImportDeclaration "import com.amazonaws.event.ProgressListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.event.ProgressListenerChain{ImportPackage} : ImportDeclaration "import com.amazonaws.event.ProgressListenerChain;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3Client{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3Client;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3EncryptionClient{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3EncryptionClient;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.internal.Mimetypes{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.internal.Mimetypes;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.internal.ServiceUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.internal.ServiceUtils;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.AbortMultipartUploadRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.AbortMultipartUploadRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.GetObjectRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.GetObjectRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ListMultipartUploadsRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ListMultipartUploadsRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ListObjectsRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ListObjectsRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.MultipartUpload{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.MultipartUpload;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.MultipartUploadListing{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.MultipartUploadListing;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ObjectListing{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ObjectListing;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ObjectMetadata{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ObjectMetadata;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.PutObjectRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.PutObjectRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.S3Object{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.S3Object;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.S3ObjectSummary{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.S3ObjectSummary;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.Transfer.TransferState{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.Transfer.TransferState;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.DownloadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.DownloadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.DownloadMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.DownloadMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferManagerUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferManagerUtils;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferProgressImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferProgressImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadCallable{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadCallable;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.util.VersionInfoUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.util.VersionInfoUtils;" compose:Replacement merge: Default]
											[NT -> TransferManager : ClassDeclaration]
												[T -> - : Modifiers "public" compose:Replacement merge: SemanticConflict]
												[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
												[T -> TransferManager : Id "TransferManager" compose:Replacement merge: Default]
												[T -> s3 : FieldDecl "private AmazonS3 s3;" compose:Replacement merge: SemanticConflict]
												[T -> configuration : FieldDecl "private TransferManagerConfiguration configuration;" compose:Replacement merge: SemanticConflict]
												[T -> threadPool : FieldDecl "private ThreadPoolExecutor threadPool;" compose:Replacement merge: SemanticConflict]
												[T -> timedThreadPool : FieldDecl "private ScheduledExecutorService timedThreadPool = new ScheduledThreadPoolExecutor(1);" compose:Replacement merge: SemanticConflict]
												[T -> log : FieldDecl "private static final Log log = LogFactory.getLog(TransferManager.class);" compose:Replacement merge: SemanticConflict]
												[T -> TransferManager(AWSCredentials-AWSCredentials) : ConstructorDecl "public TransferManager(AWSCredentials credentials) {         this(new AmazonS3Client(credentials));     }" compose:Replacement merge: LineBased]
												[T -> TransferManager(AmazonS3-AmazonS3) : ConstructorDecl "public TransferManager(AmazonS3 s3) {         this(s3, TransferManagerUtils.createDefaultExecutorService());     }" compose:Replacement merge: LineBased]
												[T -> TransferManager(AmazonS3-AmazonS3-ThreadPoolExecutor-ThreadPoolExecutor) : ConstructorDecl "public TransferManager(AmazonS3 s3, ThreadPoolExecutor threadPool) {         this.s3 = s3;         this.threadPool = threadPool;         this.configuration = new TransferManagerConfiguration();     }" compose:Replacement merge: LineBased]
												[T -> setConfiguration(TransferManagerConfiguration-TransferManagerConfiguration) : MethodDecl "public void setConfiguration(TransferManagerConfiguration configuration) {         this.configuration = configuration;     }" compose:Replacement merge: LineBased]
												[T -> getConfiguration({FormalParametersInternal}) : MethodDecl "public TransferManagerConfiguration getConfiguration() {         return configuration;     }" compose:Replacement merge: LineBased]
												[T -> getAmazonS3Client({FormalParametersInternal}) : MethodDecl "public AmazonS3 getAmazonS3Client() {         return s3;     }" compose:Replacement merge: LineBased]
												[T -> upload(String-String-String-String-InputStream-InputStream-ObjectMetadata-ObjectMetadata) : MethodDecl "public Upload upload(final String bucketName, final String key, final InputStream input, ObjectMetadata objectMetadata)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, input, objectMetadata));     }" compose:Replacement merge: LineBased]
												[T -> upload(String-String-String-String-File-File) : MethodDecl "public Upload upload(final String bucketName, final String key, final File file)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, file));     }" compose:Replacement merge: LineBased]
												[T -> upload(PutObjectRequest-PutObjectRequest) : MethodDecl "public Upload upload(final PutObjectRequest putObjectRequest)         throws AmazonServiceException, AmazonClientException {         return upload(putObjectRequest, null);     }" compose:Replacement merge: LineBased]
												[T -> upload(PutObjectRequest-PutObjectRequest-TransferStateChangeListener-TransferStateChangeListener) : MethodDecl "private Upload upload(final PutObjectRequest putObjectRequest, final TransferStateChangeListener stateListener)             throws AmazonServiceException, AmazonClientException {              appendUserAgent(putObjectRequest, USER_AGENT);              if (putObjectRequest.getMetadata() == null)                 putObjectRequest.setMetadata(new ObjectMetadata());             ObjectMetadata metadata = putObjectRequest.getMetadata();              if ( TransferManagerUtils.getRequestFile(putObjectRequest) != null ) {                 File file = TransferManagerUtils.getRequestFile(putObjectRequest);                  // Always set the content length, even if it's already set                 metadata.setContentLength(file.length());                  // Only set the content type if it hasn't already been set                 if ( metadata.getContentType() == null ) {                     metadata.setContentType(Mimetypes.getInstance().getMimetype(file));                 }             }              String description = "Uploading to " + putObjectRequest.getBucketName() + "/" + putObjectRequest.getKey();             TransferProgressImpl transferProgress = new TransferProgressImpl();             transferProgress.setTotalBytesToTransfer(TransferManagerUtils.getContentLength(putObjectRequest));              ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                     transferProgress), putObjectRequest.getGeneralProgressListener());             putObjectRequest.setGeneralProgressListener(listenerChain);              UploadImpl upload = new UploadImpl(description, transferProgress, listenerChain, stateListener);              UploadCallable uploadCallable = new UploadCallable(this, threadPool, upload, putObjectRequest, listenerChain);             UploadMonitor watcher = new UploadMonitor(this, upload, threadPool, uploadCallable, putObjectRequest, listenerChain);             watcher.setTimedThreadPool(timedThreadPool);             upload.setMonitor(watcher);              return upload;         }" compose:Replacement merge: LineBased]
												[T -> download(String-String-String-String-File-File) : MethodDecl "public Download download(String bucket, String key, File file) {         return download(new GetObjectRequest(bucket, key), file);     }" compose:Replacement merge: LineBased]
												[T -> download(GetObjectRequest-GetObjectRequest-File-File) : MethodDecl "public Download download(final GetObjectRequest getObjectRequest, final File file) {         return download(getObjectRequest, file, null);     }" compose:Replacement merge: LineBased]
												[T -> download(GetObjectRequest-GetObjectRequest-File-File-TransferStateChangeListener-TransferStateChangeListener) : MethodDecl "private Download download(final GetObjectRequest getObjectRequest,                               final File file,                               final TransferStateChangeListener stateListener) {          appendUserAgent(getObjectRequest, USER_AGENT);          String description = "Downloading from " + getObjectRequest.getBucketName() + "/" + getObjectRequest.getKey();          // Add our own transfer progress listener         TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                 transferProgress), getObjectRequest.getGeneralProgressListener());         getObjectRequest.setGeneralProgressListener(listenerChain);         final ObjectMetadata objectMetadata = s3.getObjectMetadata(getObjectRequest.getBucketName(), getObjectRequest.getKey());          final StartDownloadLock startDownloadLock = new StartDownloadLock();         final DownloadImpl download = new DownloadImpl(description, transferProgress, listenerChain, null, stateListener);         long contentLength = objectMetadata.getContentLength();         if (getObjectRequest.getRange() != null && getObjectRequest.getRange().length == 2) {             long startingByte = getObjectRequest.getRange()[0];             long lastByte     = getObjectRequest.getRange()[1];             contentLength     = lastByte - startingByte;         }          transferProgress.setTotalBytesToTransfer(contentLength);          Future<?> future = threadPool.submit(new Callable<Object>() {             @Override             public Object call() throws Exception {                 try {                     synchronized (startDownloadLock) {                         if ( !startDownloadLock.downloadReady ) {                                 try {                                     startDownloadLock.wait();                                     } catch ( InterruptedException e ) {                                  throw new AmazonClientException("Couldn't wait for setting future into the monitor");                              }                          }                      }                     download.setState(TransferState.InProgress);                     S3Object s3Object = ServiceUtils.retryableDownloadS3ObjectToFile(file, new ServiceUtils.RetryableS3DownloadTask() {                                                  @Override                         public S3Object getS3ObjectStream() {                             S3Object s3Object = s3.getObject(getObjectRequest);                             download.setS3Object(s3Object);                             return s3Object;                         }                                                  @Override                         public boolean needIntegrityCheck() {                             // Don't perform the integrity check if the stream data is wrapped                             // in a decryption stream, or if we're only looking at a range of                             // the data, since otherwise the checksum won't match up.                             boolean performIntegrityCheck = true;                             if (getObjectRequest.getRange() != null) performIntegrityCheck = false;                             if (s3 instanceof AmazonS3EncryptionClient) performIntegrityCheck = false;                             return performIntegrityCheck;                         }                     });                                           if (s3Object == null) {                         download.setState(TransferState.Canceled);                         download.setMonitor(new DownloadMonitor(download, null));                         return download;                     }                       download.setState(TransferState.Completed);                     return true;                 } catch (Exception e) {                     // Downloads aren't allowed to move from canceled to failed                     if (download.getState() != TransferState.Canceled) {                         download.setState(TransferState.Failed);                     }                     throw e;                 }             }         });         download.setMonitor(new DownloadMonitor(download, future));         synchronized (startDownloadLock) {             startDownloadLock.downloadReady = true;             startDownloadLock.notify();         }         return download;     }" compose:Replacement merge: LineBased]
												[T -> downloadDirectory(String-String-String-String-File-File) : MethodDecl "public MultipleFileDownload downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory) {          if ( keyPrefix == null )             keyPrefix = "";          List<S3ObjectSummary> objectSummaries = new LinkedList<S3ObjectSummary>();         Stack<String> commonPrefixes = new Stack<String>();         commonPrefixes.add(keyPrefix);         long totalSize = 0;          // Recurse all virtual subdirectories to get a list of object summaries.         // This is a depth-first search.         do {             String prefix = commonPrefixes.pop();             ObjectListing listObjectsResponse = null;              do {                 if ( listObjectsResponse == null ) {                     ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName)                             .withDelimiter(DEFAULT_DELIMITER).withPrefix(prefix);                     listObjectsResponse = s3.listObjects(listObjectsRequest);                 } else {                     listObjectsResponse = s3.listNextBatchOfObjects(listObjectsResponse);                 }                  for ( S3ObjectSummary s : listObjectsResponse.getObjectSummaries() ) {                     // Skip any files that are also virtual directories, since                     // we can't save both a directory and a file of the same                     // name.                     if ( !s.getKey().equals(prefix)                             && !listObjectsResponse.getCommonPrefixes().contains(s.getKey() + DEFAULT_DELIMITER) ) {                         objectSummaries.add(s);                         totalSize += s.getSize();                     } else {                         log.debug("Skipping download for object " + s.getKey()                                 + " since it is also a virtual directory");                     }                 }                  commonPrefixes.addAll(listObjectsResponse.getCommonPrefixes());             } while ( listObjectsResponse.isTruncated() );         } while ( !commonPrefixes.isEmpty() );          TransferProgressImpl transferProgress = new TransferProgressImpl();         transferProgress.setTotalBytesToTransfer(totalSize);         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<DownloadImpl> downloads = new ArrayList<DownloadImpl>();          String description = "Downloading from " + bucketName + "/" + keyPrefix;         final MultipleFileDownloadImpl multipleFileDownload = new MultipleFileDownloadImpl(description, transferProgress,                 new ProgressListenerChain(listener), keyPrefix, bucketName, downloads);         multipleFileDownload.setMonitor(new MultipleFileTransferMonitor(multipleFileDownload, downloads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileDownload);          for ( S3ObjectSummary summary : objectSummaries ) {             // TODO: non-standard delimiters             File f = new File(destinationDirectory, summary.getKey());             File parentFile = f.getParentFile();             if ( !parentFile.exists() && !parentFile.mkdirs() ) {                 throw new RuntimeException("Couldn't create parent directories for " + f.getAbsolutePath());             }              downloads.add((DownloadImpl) download(                     new GetObjectRequest(summary.getBucketName(), summary.getKey()).withGeneralProgressListener(listener), f,                     stateChangeListener));         }          if ( downloads.isEmpty() ) {             multipleFileDownload.setState(TransferState.Completed);             return multipleFileDownload;         }          // Notify all state changes waiting for the downloads to all be queued         // to wake up and continue.         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileDownload;     }" compose:Replacement merge: LineBased]
												[NT -> AllDownloadsQueuedLock : InnerClassDecl]
													[T -> - : Modifiers "private static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> AllDownloadsQueuedLock : Id "AllDownloadsQueuedLock" compose:Replacement merge: Default]
													[T -> allQueued : FieldDecl "private volatile boolean allQueued = false;" compose:Replacement merge: SemanticConflict]
												[NT -> StartDownloadLock : InnerClassDecl]
													[T -> - : Modifiers "private  static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> StartDownloadLock : Id "StartDownloadLock" compose:Replacement merge: Default]
													[T -> downloadReady : FieldDecl "private volatile boolean downloadReady = false;" compose:Replacement merge: SemanticConflict]
												[NT -> MultipleFileTransferStateChangeListener : InnerClassDecl]
													[T -> - : Modifiers "private static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> MultipleFileTransferStateChangeListener : Id "MultipleFileTransferStateChangeListener" compose:Replacement merge: Default]
													[T -> ImplList : ImplementsList "implements TransferStateChangeListener" compose:Replacement merge: SemanticConflict]
													[T -> allTransfersQueuedLock : FieldDecl "private final AllDownloadsQueuedLock allTransfersQueuedLock;" compose:Replacement merge: SemanticConflict]
													[T -> multipleFileTransfer : FieldDecl "private final MultipleFileTransfer multipleFileTransfer;" compose:Replacement merge: SemanticConflict]
													[T -> MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock-AllDownloadsQueuedLock-MultipleFileTransfer-MultipleFileTransfer) : ConstructorDecl "public MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock allTransfersQueuedLock,                 MultipleFileTransfer multipleFileDownload) {             this.allTransfersQueuedLock = allTransfersQueuedLock;             this.multipleFileTransfer = multipleFileDownload;         }" compose:Replacement merge: LineBased]
													[T -> transferStateChanged(Transfer-Transfer-TransferState-TransferState) : MethodDecl "@Override         public void transferStateChanged(Transfer upload, TransferState state) {              // There's a race here: we can't start monitoring the state of             // individual transfers until we have added all the transfers to the             // list, or we may incorrectly report completion.             synchronized (allTransfersQueuedLock) {                 if ( !allTransfersQueuedLock.allQueued ) {                     try {                         allTransfersQueuedLock.wait();                     } catch ( InterruptedException e ) {                         throw new AmazonClientException("Couldn't wait for all downloads to be queued");                     }                 }             }              synchronized (multipleFileTransfer) {                 if ( multipleFileTransfer.getState() == state || multipleFileTransfer.isDone() )                     return;                  /*                  * If we're not already in a terminal state, allow a transition                  * to a non-waiting state. Mark completed if this download is                  * completed and the monitor says all of the rest are as well.                  */                 if ( state == TransferState.InProgress ) {                     multipleFileTransfer.setState(state);                 } else if ( multipleFileTransfer.getMonitor().isDone() ) {                     multipleFileTransfer.collateFinalState();                 } else {                     multipleFileTransfer.setState(TransferState.InProgress);                 }             }         }" compose:Replacement merge: LineBased]
												[T -> auto1 : EmptyDecl ";" compose:Replacement merge: Default]
												[T -> uploadDirectory(String-String-String-String-File-File-boolean-boolean) : MethodDecl "public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories) {      return uploadDirectory(bucketName, virtualDirectoryKeyPrefix, directory, includeSubdirectories, null);     }" compose:Replacement merge: LineBased]
												[T -> uploadDirectory(String-String-String-String-File-File-boolean-boolean-ObjectMetadataProvider-ObjectMetadataProvider) : MethodDecl "public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories, ObjectMetadataProvider metadataProvider) {      if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a directory to upload");         }          List<File> files = new LinkedList<File>();         listFiles(directory, files, includeSubdirectories);                  return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, metadataProvider);     }" compose:Replacement merge: LineBased]
												[T -> uploadFileList(String-String-String-String-File-File-List<File>-List<File>) : MethodDecl "public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files) {           return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, null);     }" compose:Replacement merge: LineBased]
												[T -> uploadFileList(String-String-String-String-File-File-List<File>-List<File>-ObjectMetadataProvider-ObjectMetadataProvider) : MethodDecl "public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files,ObjectMetadataProvider metadataProvider) {          if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a common base directory for uploaded files");         }          if (virtualDirectoryKeyPrefix == null || virtualDirectoryKeyPrefix.length() == 0) {             virtualDirectoryKeyPrefix = "";         } else if ( !virtualDirectoryKeyPrefix.endsWith("/") ) {             virtualDirectoryKeyPrefix = virtualDirectoryKeyPrefix + "/";         }          TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<UploadImpl> uploads = new LinkedList<UploadImpl>();         MultipleFileUploadImpl multipleFileUpload = new MultipleFileUploadImpl("Uploading etc", transferProgress, (ProgressListenerChain)null, virtualDirectoryKeyPrefix, bucketName, uploads);         multipleFileUpload.setMonitor(new MultipleFileTransferMonitor(multipleFileUpload, uploads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileUpload);          if ( files == null || files.isEmpty()) {             multipleFileUpload.setState(TransferState.Completed);         }          long totalSize = 0;         for (File f : files) {             //Check, if file, since only files can be uploaded.             if (f.isFile()) {                 totalSize += f.length();                 String key = f.getAbsolutePath().substring(directory.getAbsolutePath().length() + 1)                         .replaceAll("\\\\", "/");                                  ObjectMetadata metadata=new ObjectMetadata();                                  // Invoke the callback if it's present.                 // The callback allows the user to customize the metadata for each file being uploaded.                 if(metadataProvider!=null){                    metadataProvider.provideObjectMetadata(f,metadata);                 }                                  uploads.add((UploadImpl) upload(                         new PutObjectRequest(bucketName, virtualDirectoryKeyPrefix + key, f).withMetadata(metadata).withGeneralProgressListener(listener),                         stateChangeListener));             }         }          transferProgress.setTotalBytesToTransfer(totalSize);          // Notify all state changes waiting for the uploads to all be queued         // to wake up and continue         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileUpload;     }" compose:Replacement merge: LineBased]
												[T -> listFiles(File-File-List<File>-List<File>-boolean-boolean) : MethodDecl "private void listFiles(File dir, List<File> results, boolean includeSubDirectories) {         File[] found = dir.listFiles();         if ( found != null ) {             for ( File f : found ) {                 if (f.isDirectory()) {                     if (includeSubDirectories) {                         listFiles(f, results, includeSubDirectories);                     }                 } else {                     results.add(f);                 }             }         }     }" compose:Replacement merge: LineBased]
												[T -> abortMultipartUploads(String-String-Date-Date) : MethodDecl "public void abortMultipartUploads(String bucketName, Date date)             throws AmazonServiceException, AmazonClientException {         MultipartUploadListing uploadListing = s3.listMultipartUploads(appendUserAgent(                 new ListMultipartUploadsRequest(bucketName), USER_AGENT));         do {             for (MultipartUpload upload : uploadListing.getMultipartUploads()) {                 if (upload.getInitiated().compareTo(date) < 0) {                     s3.abortMultipartUpload(appendUserAgent(new AbortMultipartUploadRequest(                             bucketName, upload.getKey(), upload.getUploadId()), USER_AGENT));                 }             }              ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName)                 .withUploadIdMarker(uploadListing.getNextUploadIdMarker())                 .withKeyMarker(uploadListing.getNextKeyMarker());             uploadListing = s3.listMultipartUploads(appendUserAgent(request, USER_AGENT));         } while (uploadListing.isTruncated());     }" compose:Replacement merge: LineBased]
												[T -> shutdownNow({FormalParametersInternal}) : MethodDecl "public void shutdownNow() {         threadPool.shutdownNow();         timedThreadPool.shutdownNow();          if (s3 instanceof AmazonS3Client) {             ((AmazonS3Client)s3).shutdown();         }     }" compose:Replacement merge: LineBased]
												[T -> appendUserAgent(X-X-String-String) : MethodDecl "public <X extends AmazonWebServiceRequest> X appendUserAgent(X request, String userAgent) {         request.getRequestClientOptions().addClientMarker(USER_AGENT);         return request;     }" compose:Replacement merge: LineBased]
												[T -> USER_AGENT : FieldDecl "private static final String USER_AGENT = TransferManager.class.getName() + "/" + VersionInfoUtils.getVersion();" compose:Replacement merge: SemanticConflict]
												[T -> DEFAULT_DELIMITER : FieldDecl "private static final String DEFAULT_DELIMITER = "/";" compose:Replacement merge: SemanticConflict]
[NT -> base : Feature]
	[NT -> src : Folder]
		[NT -> main : Folder]
			[NT -> java : Folder]
				[NT -> com : Folder]
					[NT -> amazonaws : Folder]
						[NT -> services : Folder]
							[NT -> s3 : Folder]
								[NT -> transfer : Folder]
									[NT -> TransferManager.java : Java-File]
										[NT -> - : CompilationUnit]
											[T -> - : PackageDeclaration "package com.amazonaws.services.s3.transfer;" compose:Replacement merge: Default]
											[T -> java.io.File{ImportPackage} : ImportDeclaration "import java.io.File;" compose:Replacement merge: Default]
											[T -> java.io.InputStream{ImportPackage} : ImportDeclaration "import java.io.InputStream;" compose:Replacement merge: Default]
											[T -> java.util.ArrayList{ImportPackage} : ImportDeclaration "import java.util.ArrayList;" compose:Replacement merge: Default]
											[T -> java.util.Date{ImportPackage} : ImportDeclaration "import java.util.Date;" compose:Replacement merge: Default]
											[T -> java.util.LinkedList{ImportPackage} : ImportDeclaration "import java.util.LinkedList;" compose:Replacement merge: Default]
											[T -> java.util.List{ImportPackage} : ImportDeclaration "import java.util.List;" compose:Replacement merge: Default]
											[T -> java.util.Stack{ImportPackage} : ImportDeclaration "import java.util.Stack;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.Callable{ImportPackage} : ImportDeclaration "import java.util.concurrent.Callable;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.Future{ImportPackage} : ImportDeclaration "import java.util.concurrent.Future;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ScheduledExecutorService{ImportPackage} : ImportDeclaration "import java.util.concurrent.ScheduledExecutorService;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ScheduledThreadPoolExecutor{ImportPackage} : ImportDeclaration "import java.util.concurrent.ScheduledThreadPoolExecutor;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ThreadPoolExecutor{ImportPackage} : ImportDeclaration "import java.util.concurrent.ThreadPoolExecutor;" compose:Replacement merge: Default]
											[T -> org.apache.commons.logging.Log{ImportPackage} : ImportDeclaration "import org.apache.commons.logging.Log;" compose:Replacement merge: Default]
											[T -> org.apache.commons.logging.LogFactory{ImportPackage} : ImportDeclaration "import org.apache.commons.logging.LogFactory;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonClientException{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonClientException;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonServiceException{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonServiceException;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonWebServiceRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonWebServiceRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.auth.AWSCredentials{ImportPackage} : ImportDeclaration "import com.amazonaws.auth.AWSCredentials;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3Client{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3Client;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3EncryptionClient{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3EncryptionClient;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.internal.Mimetypes{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.internal.Mimetypes;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.internal.ServiceUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.internal.ServiceUtils;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.AbortMultipartUploadRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.AbortMultipartUploadRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.GetObjectRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.GetObjectRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ListMultipartUploadsRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ListMultipartUploadsRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ListObjectsRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ListObjectsRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.MultipartUpload{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.MultipartUpload;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.MultipartUploadListing{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.MultipartUploadListing;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ObjectListing{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ObjectListing;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ObjectMetadata{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ObjectMetadata;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ProgressListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ProgressListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.PutObjectRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.PutObjectRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.S3Object{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.S3Object;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.S3ObjectSummary{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.S3ObjectSummary;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.Transfer.TransferState{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.Transfer.TransferState;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.DownloadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.DownloadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.DownloadMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.DownloadMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.ProgressListenerChain{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.ProgressListenerChain;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferManagerUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferManagerUtils;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferProgressImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferProgressImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadCallable{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadCallable;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.util.VersionInfoUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.util.VersionInfoUtils;" compose:Replacement merge: Default]
											[NT -> TransferManager : ClassDeclaration]
												[T -> - : Modifiers "public" compose:Replacement merge: SemanticConflict]
												[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
												[T -> TransferManager : Id "TransferManager" compose:Replacement merge: Default]
												[T -> s3 : FieldDecl "private AmazonS3 s3;" compose:Replacement merge: SemanticConflict]
												[T -> configuration : FieldDecl "private TransferManagerConfiguration configuration;" compose:Replacement merge: SemanticConflict]
												[T -> threadPool : FieldDecl "private ThreadPoolExecutor threadPool;" compose:Replacement merge: SemanticConflict]
												[T -> timedThreadPool : FieldDecl "private ScheduledExecutorService timedThreadPool = new ScheduledThreadPoolExecutor(1);" compose:Replacement merge: SemanticConflict]
												[T -> log : FieldDecl "private static final Log log = LogFactory.getLog(TransferManager.class);" compose:Replacement merge: SemanticConflict]
												[T -> TransferManager(AWSCredentials-AWSCredentials) : ConstructorDecl "public TransferManager(AWSCredentials credentials) {         this(new AmazonS3Client(credentials));     }" compose:Replacement merge: LineBased]
												[T -> TransferManager(AmazonS3-AmazonS3) : ConstructorDecl "public TransferManager(AmazonS3 s3) {         this(s3, TransferManagerUtils.createDefaultExecutorService());     }" compose:Replacement merge: LineBased]
												[T -> TransferManager(AmazonS3-AmazonS3-ThreadPoolExecutor-ThreadPoolExecutor) : ConstructorDecl "public TransferManager(AmazonS3 s3, ThreadPoolExecutor threadPool) {         this.s3 = s3;         this.threadPool = threadPool;         this.configuration = new TransferManagerConfiguration();     }" compose:Replacement merge: LineBased]
												[T -> setConfiguration(TransferManagerConfiguration-TransferManagerConfiguration) : MethodDecl "public void setConfiguration(TransferManagerConfiguration configuration) {         this.configuration = configuration;     }" compose:Replacement merge: LineBased]
												[T -> getConfiguration({FormalParametersInternal}) : MethodDecl "public TransferManagerConfiguration getConfiguration() {         return configuration;     }" compose:Replacement merge: LineBased]
												[T -> getAmazonS3Client({FormalParametersInternal}) : MethodDecl "public AmazonS3 getAmazonS3Client() {         return s3;     }" compose:Replacement merge: LineBased]
												[T -> upload(String-String-String-String-InputStream-InputStream-ObjectMetadata-ObjectMetadata) : MethodDecl "public Upload upload(final String bucketName, final String key, final InputStream input, ObjectMetadata objectMetadata)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, input, objectMetadata));     }" compose:Replacement merge: LineBased]
												[T -> upload(String-String-String-String-File-File) : MethodDecl "public Upload upload(final String bucketName, final String key, final File file)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, file));     }" compose:Replacement merge: LineBased]
												[T -> upload(PutObjectRequest-PutObjectRequest) : MethodDecl "public Upload upload(final PutObjectRequest putObjectRequest)         throws AmazonServiceException, AmazonClientException {         return upload(putObjectRequest, null);     }" compose:Replacement merge: LineBased]
												[T -> upload(PutObjectRequest-PutObjectRequest-TransferStateChangeListener-TransferStateChangeListener) : MethodDecl "private Upload upload(final PutObjectRequest putObjectRequest, final TransferStateChangeListener stateListener)             throws AmazonServiceException, AmazonClientException {              appendUserAgent(putObjectRequest, USER_AGENT);              if (putObjectRequest.getMetadata() == null)                 putObjectRequest.setMetadata(new ObjectMetadata());             ObjectMetadata metadata = putObjectRequest.getMetadata();              if ( TransferManagerUtils.getRequestFile(putObjectRequest) != null ) {                 File file = TransferManagerUtils.getRequestFile(putObjectRequest);                  // Always set the content length, even if it's already set                 metadata.setContentLength(file.length());                  // Only set the content type if it hasn't already been set                 if ( metadata.getContentType() == null ) {                     metadata.setContentType(Mimetypes.getInstance().getMimetype(file));                 }             }              String description = "Uploading to " + putObjectRequest.getBucketName() + "/" + putObjectRequest.getKey();             TransferProgressImpl transferProgress = new TransferProgressImpl();             transferProgress.setTotalBytesToTransfer(TransferManagerUtils.getContentLength(putObjectRequest));              ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                     transferProgress), putObjectRequest.getProgressListener());             putObjectRequest.setProgressListener(listenerChain);              UploadImpl upload = new UploadImpl(description, transferProgress, listenerChain, stateListener);              UploadCallable uploadCallable = new UploadCallable(this, threadPool, upload, putObjectRequest, listenerChain);             UploadMonitor watcher = new UploadMonitor(this, upload, threadPool, uploadCallable, putObjectRequest, listenerChain);             watcher.setTimedThreadPool(timedThreadPool);             upload.setMonitor(watcher);              return upload;         }" compose:Replacement merge: LineBased]
												[T -> download(String-String-String-String-File-File) : MethodDecl "public Download download(String bucket, String key, File file) {         return download(new GetObjectRequest(bucket, key), file);     }" compose:Replacement merge: LineBased]
												[T -> download(GetObjectRequest-GetObjectRequest-File-File) : MethodDecl "public Download download(final GetObjectRequest getObjectRequest, final File file) {         return download(getObjectRequest, file, null);     }" compose:Replacement merge: LineBased]
												[T -> download(GetObjectRequest-GetObjectRequest-File-File-TransferStateChangeListener-TransferStateChangeListener) : MethodDecl "private Download download(final GetObjectRequest getObjectRequest,                               final File file,                               final TransferStateChangeListener stateListener) {          appendUserAgent(getObjectRequest, USER_AGENT);          String description = "Downloading from " + getObjectRequest.getBucketName() + "/" + getObjectRequest.getKey();          // Add our own transfer progress listener         TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                 transferProgress), getObjectRequest.getProgressListener());         getObjectRequest.setProgressListener(listenerChain);         final ObjectMetadata objectMetadata = s3.getObjectMetadata(getObjectRequest.getBucketName(), getObjectRequest.getKey());          final StartDownloadLock startDownloadLock = new StartDownloadLock();         final DownloadImpl download = new DownloadImpl(description, transferProgress, listenerChain, null, stateListener);         long contentLength = objectMetadata.getContentLength();         if (getObjectRequest.getRange() != null && getObjectRequest.getRange().length == 2) {             long startingByte = getObjectRequest.getRange()[0];             long lastByte     = getObjectRequest.getRange()[1];             contentLength     = lastByte - startingByte;         }          transferProgress.setTotalBytesToTransfer(contentLength);          Future<?> future = threadPool.submit(new Callable<Object>() {             @Override             public Object call() throws Exception {                 try {                     synchronized (startDownloadLock) {                         if ( !startDownloadLock.downloadReady ) {                                 try {                                     startDownloadLock.wait();                                     } catch ( InterruptedException e ) {                                  throw new AmazonClientException("Couldn't wait for setting future into the monitor");                              }                          }                      }                     download.setState(TransferState.InProgress);                     S3Object s3Object = ServiceUtils.retryableDownloadS3ObjectToFile(file, new ServiceUtils.RetryableS3DownloadTask() {              @Override       public S3Object getS3ObjectStream() {        S3Object s3Object = s3.getObject(getObjectRequest);        download.setS3Object(s3Object);        return s3Object;       }              @Override       public boolean needIntegrityCheck() {                       // Don't perform the integrity check if the stream data is wrapped                       // in a decryption stream, or if we're only looking at a range of                       // the data, since otherwise the checksum won't match up.                       boolean performIntegrityCheck = true;                       if (getObjectRequest.getRange() != null) performIntegrityCheck = false;                       if (s3 instanceof AmazonS3EncryptionClient) performIntegrityCheck = false;                       return performIntegrityCheck;           }      });                                           if (s3Object == null) {                         download.setState(TransferState.Canceled);                         download.setMonitor(new DownloadMonitor(download, null));                         return download;                     }                       download.setState(TransferState.Completed);                     return true;                 } catch (Exception e) {                     // Downloads aren't allowed to move from canceled to failed                     if (download.getState() != TransferState.Canceled) {                         download.setState(TransferState.Failed);                     }                     throw e;                 }             }         });         download.setMonitor(new DownloadMonitor(download, future));         synchronized (startDownloadLock) {             startDownloadLock.downloadReady = true;             startDownloadLock.notify();         }         return download;     }" compose:Replacement merge: LineBased]
												[T -> downloadDirectory(String-String-String-String-File-File) : MethodDecl "public MultipleFileDownload downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory) {          if ( keyPrefix == null )             keyPrefix = "";          List<S3ObjectSummary> objectSummaries = new LinkedList<S3ObjectSummary>();         Stack<String> commonPrefixes = new Stack<String>();         commonPrefixes.add(keyPrefix);         long totalSize = 0;          // Recurse all virtual subdirectories to get a list of object summaries.         // This is a depth-first search.         do {             String prefix = commonPrefixes.pop();             ObjectListing listObjectsResponse = null;              do {                 if ( listObjectsResponse == null ) {                     ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName)                             .withDelimiter(DEFAULT_DELIMITER).withPrefix(prefix);                     listObjectsResponse = s3.listObjects(listObjectsRequest);                 } else {                     listObjectsResponse = s3.listNextBatchOfObjects(listObjectsResponse);                 }                  for ( S3ObjectSummary s : listObjectsResponse.getObjectSummaries() ) {                     // Skip any files that are also virtual directories, since                     // we can't save both a directory and a file of the same                     // name.                     if ( !s.getKey().equals(prefix)                             && !listObjectsResponse.getCommonPrefixes().contains(s.getKey() + DEFAULT_DELIMITER) ) {                         objectSummaries.add(s);                         totalSize += s.getSize();                     } else {                         log.debug("Skipping download for object " + s.getKey()                                 + " since it is also a virtual directory");                     }                 }                  commonPrefixes.addAll(listObjectsResponse.getCommonPrefixes());             } while ( listObjectsResponse.isTruncated() );         } while ( !commonPrefixes.isEmpty() );          TransferProgressImpl transferProgress = new TransferProgressImpl();         transferProgress.setTotalBytesToTransfer(totalSize);         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<DownloadImpl> downloads = new ArrayList<DownloadImpl>();          String description = "Downloading from " + bucketName + "/" + keyPrefix;         final MultipleFileDownloadImpl multipleFileDownload = new MultipleFileDownloadImpl(description, transferProgress,                 new ProgressListenerChain(listener), keyPrefix, bucketName, downloads);         multipleFileDownload.setMonitor(new MultipleFileTransferMonitor(multipleFileDownload, downloads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileDownload);          for ( S3ObjectSummary summary : objectSummaries ) {             // TODO: non-standard delimiters             File f = new File(destinationDirectory, summary.getKey());             File parentFile = f.getParentFile();             if ( !parentFile.exists() && !parentFile.mkdirs() ) {                 throw new RuntimeException("Couldn't create parent directories for " + f.getAbsolutePath());             }              downloads.add((DownloadImpl) download(                     new GetObjectRequest(summary.getBucketName(), summary.getKey()).withProgressListener(listener), f,                     stateChangeListener));         }          if ( downloads.isEmpty() ) {             multipleFileDownload.setState(TransferState.Completed);             return multipleFileDownload;         }          // Notify all state changes waiting for the downloads to all be queued         // to wake up and continue.         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileDownload;     }" compose:Replacement merge: LineBased]
												[NT -> AllDownloadsQueuedLock : InnerClassDecl]
													[T -> - : Modifiers "private static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> AllDownloadsQueuedLock : Id "AllDownloadsQueuedLock" compose:Replacement merge: Default]
													[T -> allQueued : FieldDecl "private volatile boolean allQueued = false;" compose:Replacement merge: SemanticConflict]
												[NT -> StartDownloadLock : InnerClassDecl]
													[T -> - : Modifiers "private  static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> StartDownloadLock : Id "StartDownloadLock" compose:Replacement merge: Default]
													[T -> downloadReady : FieldDecl "private volatile boolean downloadReady = false;" compose:Replacement merge: SemanticConflict]
												[NT -> MultipleFileTransferStateChangeListener : InnerClassDecl]
													[T -> - : Modifiers "private static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> MultipleFileTransferStateChangeListener : Id "MultipleFileTransferStateChangeListener" compose:Replacement merge: Default]
													[T -> ImplList : ImplementsList "implements TransferStateChangeListener" compose:Replacement merge: SemanticConflict]
													[T -> allTransfersQueuedLock : FieldDecl "private final AllDownloadsQueuedLock allTransfersQueuedLock;" compose:Replacement merge: SemanticConflict]
													[T -> multipleFileTransfer : FieldDecl "private final MultipleFileTransfer multipleFileTransfer;" compose:Replacement merge: SemanticConflict]
													[T -> MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock-AllDownloadsQueuedLock-MultipleFileTransfer-MultipleFileTransfer) : ConstructorDecl "public MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock allTransfersQueuedLock,                 MultipleFileTransfer multipleFileDownload) {             this.allTransfersQueuedLock = allTransfersQueuedLock;             this.multipleFileTransfer = multipleFileDownload;         }" compose:Replacement merge: LineBased]
													[T -> transferStateChanged(Transfer-Transfer-TransferState-TransferState) : MethodDecl "@Override         public void transferStateChanged(Transfer upload, TransferState state) {              // There's a race here: we can't start monitoring the state of             // individual transfers until we have added all the transfers to the             // list, or we may incorrectly report completion.             synchronized (allTransfersQueuedLock) {                 if ( !allTransfersQueuedLock.allQueued ) {                     try {                         allTransfersQueuedLock.wait();                     } catch ( InterruptedException e ) {                         throw new AmazonClientException("Couldn't wait for all downloads to be queued");                     }                 }             }              synchronized (multipleFileTransfer) {                 if ( multipleFileTransfer.getState() == state || multipleFileTransfer.isDone() )                     return;                  /*                  * If we're not already in a terminal state, allow a transition                  * to a non-waiting state. Mark completed if this download is                  * completed and the monitor says all of the rest are as well.                  */                 if ( state == TransferState.InProgress ) {                     multipleFileTransfer.setState(state);                 } else if ( multipleFileTransfer.getMonitor().isDone() ) {                     multipleFileTransfer.collateFinalState();                 } else {                     multipleFileTransfer.setState(TransferState.InProgress);                 }             }         }" compose:Replacement merge: LineBased]
												[T -> auto2 : EmptyDecl ";" compose:Replacement merge: Default]
												[T -> uploadDirectory(String-String-String-String-File-File-boolean-boolean) : MethodDecl "public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories) {      return uploadDirectory(bucketName, virtualDirectoryKeyPrefix, directory, includeSubdirectories, null);     }" compose:Replacement merge: LineBased]
												[T -> uploadDirectory(String-String-String-String-File-File-boolean-boolean-ObjectMetadataProvider-ObjectMetadataProvider) : MethodDecl "public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories, ObjectMetadataProvider metadataProvider) {      if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a directory to upload");         }          List<File> files = new LinkedList<File>();         listFiles(directory, files, includeSubdirectories);                  return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, metadataProvider);     }" compose:Replacement merge: LineBased]
												[T -> uploadFileList(String-String-String-String-File-File-List<File>-List<File>) : MethodDecl "public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files) {           return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, null);     }" compose:Replacement merge: LineBased]
												[T -> uploadFileList(String-String-String-String-File-File-List<File>-List<File>-ObjectMetadataProvider-ObjectMetadataProvider) : MethodDecl "public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files,ObjectMetadataProvider metadataProvider) {          if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a common base directory for uploaded files");         }          if (virtualDirectoryKeyPrefix == null || virtualDirectoryKeyPrefix.length() == 0) {             virtualDirectoryKeyPrefix = "";         } else if ( !virtualDirectoryKeyPrefix.endsWith("/") ) {             virtualDirectoryKeyPrefix = virtualDirectoryKeyPrefix + "/";         }          TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<UploadImpl> uploads = new LinkedList<UploadImpl>();         MultipleFileUploadImpl multipleFileUpload = new MultipleFileUploadImpl("Uploading etc", transferProgress, null, virtualDirectoryKeyPrefix, bucketName, uploads);         multipleFileUpload.setMonitor(new MultipleFileTransferMonitor(multipleFileUpload, uploads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileUpload);          if ( files == null || files.isEmpty()) {             multipleFileUpload.setState(TransferState.Completed);         }          long totalSize = 0;         for (File f : files) {             //Check, if file, since only files can be uploaded.             if (f.isFile()) {                 totalSize += f.length();                 String key = f.getAbsolutePath().substring(directory.getAbsolutePath().length() + 1)                         .replaceAll("\\\\", "/");                                  ObjectMetadata metadata=new ObjectMetadata();                                  // Invoke the callback if it's present.                 // The callback allows the user to customize the metadata for each file being uploaded.                 if(metadataProvider!=null){                    metadataProvider.provideObjectMetadata(f,metadata);                 }                                  uploads.add((UploadImpl) upload(                         new PutObjectRequest(bucketName, virtualDirectoryKeyPrefix + key, f).withMetadata(metadata).withProgressListener(listener),                         stateChangeListener));             }         }          transferProgress.setTotalBytesToTransfer(totalSize);          // Notify all state changes waiting for the uploads to all be queued         // to wake up and continue         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileUpload;     }" compose:Replacement merge: LineBased]
												[T -> listFiles(File-File-List<File>-List<File>-boolean-boolean) : MethodDecl "private void listFiles(File dir, List<File> results, boolean includeSubDirectories) {         File[] found = dir.listFiles();         if ( found != null ) {             for ( File f : found ) {                 if (f.isDirectory()) {                     if (includeSubDirectories) {                         listFiles(f, results, includeSubDirectories);                     }                 } else {                     results.add(f);                 }             }         }     }" compose:Replacement merge: LineBased]
												[T -> abortMultipartUploads(String-String-Date-Date) : MethodDecl "public void abortMultipartUploads(String bucketName, Date date)             throws AmazonServiceException, AmazonClientException {         MultipartUploadListing uploadListing = s3.listMultipartUploads(appendUserAgent(                 new ListMultipartUploadsRequest(bucketName), USER_AGENT));         do {             for (MultipartUpload upload : uploadListing.getMultipartUploads()) {                 if (upload.getInitiated().compareTo(date) < 0) {                     s3.abortMultipartUpload(appendUserAgent(new AbortMultipartUploadRequest(                             bucketName, upload.getKey(), upload.getUploadId()), USER_AGENT));                 }             }              ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName)                 .withUploadIdMarker(uploadListing.getNextUploadIdMarker())                 .withKeyMarker(uploadListing.getNextKeyMarker());             uploadListing = s3.listMultipartUploads(appendUserAgent(request, USER_AGENT));         } while (uploadListing.isTruncated());     }" compose:Replacement merge: LineBased]
												[T -> shutdownNow({FormalParametersInternal}) : MethodDecl "public void shutdownNow() {         threadPool.shutdownNow();         timedThreadPool.shutdownNow();          if (s3 instanceof AmazonS3Client) {             ((AmazonS3Client)s3).shutdown();         }     }" compose:Replacement merge: LineBased]
												[T -> appendUserAgent(X-X-String-String) : MethodDecl "public <X extends AmazonWebServiceRequest> X appendUserAgent(X request, String userAgent) {         request.getRequestClientOptions().addClientMarker(USER_AGENT);         return request;     }" compose:Replacement merge: LineBased]
												[T -> USER_AGENT : FieldDecl "private static final String USER_AGENT = TransferManager.class.getName() + "/" + VersionInfoUtils.getVersion();" compose:Replacement merge: SemanticConflict]
												[T -> DEFAULT_DELIMITER : FieldDecl "private static final String DEFAULT_DELIMITER = "/";" compose:Replacement merge: SemanticConflict]
[NT -> right : Feature]
	[NT -> src : Folder]
		[NT -> main : Folder]
			[NT -> java : Folder]
				[NT -> com : Folder]
					[NT -> amazonaws : Folder]
						[NT -> services : Folder]
							[NT -> s3 : Folder]
								[NT -> transfer : Folder]
									[NT -> TransferManager.java : Java-File]
										[NT -> - : CompilationUnit]
											[T -> - : PackageDeclaration "package com.amazonaws.services.s3.transfer;" compose:Replacement merge: Default]
											[T -> java.io.File{ImportPackage} : ImportDeclaration "import java.io.File;" compose:Replacement merge: Default]
											[T -> java.io.InputStream{ImportPackage} : ImportDeclaration "import java.io.InputStream;" compose:Replacement merge: Default]
											[T -> java.util.ArrayList{ImportPackage} : ImportDeclaration "import java.util.ArrayList;" compose:Replacement merge: Default]
											[T -> java.util.Date{ImportPackage} : ImportDeclaration "import java.util.Date;" compose:Replacement merge: Default]
											[T -> java.util.LinkedList{ImportPackage} : ImportDeclaration "import java.util.LinkedList;" compose:Replacement merge: Default]
											[T -> java.util.List{ImportPackage} : ImportDeclaration "import java.util.List;" compose:Replacement merge: Default]
											[T -> java.util.Stack{ImportPackage} : ImportDeclaration "import java.util.Stack;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.Callable{ImportPackage} : ImportDeclaration "import java.util.concurrent.Callable;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.Future{ImportPackage} : ImportDeclaration "import java.util.concurrent.Future;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ScheduledExecutorService{ImportPackage} : ImportDeclaration "import java.util.concurrent.ScheduledExecutorService;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ScheduledThreadPoolExecutor{ImportPackage} : ImportDeclaration "import java.util.concurrent.ScheduledThreadPoolExecutor;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ThreadPoolExecutor{ImportPackage} : ImportDeclaration "import java.util.concurrent.ThreadPoolExecutor;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.ThreadFactory{ImportPackage} : ImportDeclaration "import java.util.concurrent.ThreadFactory;" compose:Replacement merge: Default]
											[T -> java.util.concurrent.atomic.AtomicInteger{ImportPackage} : ImportDeclaration "import java.util.concurrent.atomic.AtomicInteger;" compose:Replacement merge: Default]
											[T -> org.apache.commons.logging.Log{ImportPackage} : ImportDeclaration "import org.apache.commons.logging.Log;" compose:Replacement merge: Default]
											[T -> org.apache.commons.logging.LogFactory{ImportPackage} : ImportDeclaration "import org.apache.commons.logging.LogFactory;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonClientException{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonClientException;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonServiceException{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonServiceException;" compose:Replacement merge: Default]
											[T -> com.amazonaws.AmazonWebServiceRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.AmazonWebServiceRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.auth.AWSCredentials{ImportPackage} : ImportDeclaration "import com.amazonaws.auth.AWSCredentials;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3Client{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3Client;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.AmazonS3EncryptionClient{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.AmazonS3EncryptionClient;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.internal.Mimetypes{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.internal.Mimetypes;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.internal.ServiceUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.internal.ServiceUtils;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.AbortMultipartUploadRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.AbortMultipartUploadRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.GetObjectRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.GetObjectRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ListMultipartUploadsRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ListMultipartUploadsRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ListObjectsRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ListObjectsRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.MultipartUpload{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.MultipartUpload;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.MultipartUploadListing{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.MultipartUploadListing;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ObjectListing{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ObjectListing;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ObjectMetadata{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ObjectMetadata;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.ProgressListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.ProgressListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.PutObjectRequest{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.PutObjectRequest;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.S3Object{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.S3Object;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.model.S3ObjectSummary{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.model.S3ObjectSummary;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.Transfer.TransferState{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.Transfer.TransferState;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.DownloadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.DownloadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.DownloadMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.DownloadMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.ProgressListenerChain{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.ProgressListenerChain;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferManagerUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferManagerUtils;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferProgressImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferProgressImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadCallable{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadCallable;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadImpl{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadImpl;" compose:Replacement merge: Default]
											[T -> com.amazonaws.services.s3.transfer.internal.UploadMonitor{ImportPackage} : ImportDeclaration "import com.amazonaws.services.s3.transfer.internal.UploadMonitor;" compose:Replacement merge: Default]
											[T -> com.amazonaws.util.VersionInfoUtils{ImportPackage} : ImportDeclaration "import com.amazonaws.util.VersionInfoUtils;" compose:Replacement merge: Default]
											[NT -> TransferManager : ClassDeclaration]
												[T -> - : Modifiers "public" compose:Replacement merge: SemanticConflict]
												[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
												[T -> TransferManager : Id "TransferManager" compose:Replacement merge: Default]
												[T -> s3 : FieldDecl "private AmazonS3 s3;" compose:Replacement merge: SemanticConflict]
												[T -> configuration : FieldDecl "private TransferManagerConfiguration configuration;" compose:Replacement merge: SemanticConflict]
												[T -> threadPool : FieldDecl "private ThreadPoolExecutor threadPool;" compose:Replacement merge: SemanticConflict]
												[T -> timedThreadPool : FieldDecl "private ScheduledExecutorService timedThreadPool = new ScheduledThreadPoolExecutor(1, daemonThreadFactory);" compose:Replacement merge: SemanticConflict]
												[T -> log : FieldDecl "private static final Log log = LogFactory.getLog(TransferManager.class);" compose:Replacement merge: SemanticConflict]
												[T -> TransferManager(AWSCredentials-AWSCredentials) : ConstructorDecl "public TransferManager(AWSCredentials credentials) {         this(new AmazonS3Client(credentials));     }" compose:Replacement merge: LineBased]
												[T -> TransferManager(AmazonS3-AmazonS3) : ConstructorDecl "public TransferManager(AmazonS3 s3) {         this(s3, TransferManagerUtils.createDefaultExecutorService());     }" compose:Replacement merge: LineBased]
												[T -> TransferManager(AmazonS3-AmazonS3-ThreadPoolExecutor-ThreadPoolExecutor) : ConstructorDecl "public TransferManager(AmazonS3 s3, ThreadPoolExecutor threadPool) {         this.s3 = s3;         this.threadPool = threadPool;         this.configuration = new TransferManagerConfiguration();     }" compose:Replacement merge: LineBased]
												[T -> setConfiguration(TransferManagerConfiguration-TransferManagerConfiguration) : MethodDecl "public void setConfiguration(TransferManagerConfiguration configuration) {         this.configuration = configuration;     }" compose:Replacement merge: LineBased]
												[T -> getConfiguration({FormalParametersInternal}) : MethodDecl "public TransferManagerConfiguration getConfiguration() {         return configuration;     }" compose:Replacement merge: LineBased]
												[T -> getAmazonS3Client({FormalParametersInternal}) : MethodDecl "public AmazonS3 getAmazonS3Client() {         return s3;     }" compose:Replacement merge: LineBased]
												[T -> upload(String-String-String-String-InputStream-InputStream-ObjectMetadata-ObjectMetadata) : MethodDecl "public Upload upload(final String bucketName, final String key, final InputStream input, ObjectMetadata objectMetadata)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, input, objectMetadata));     }" compose:Replacement merge: LineBased]
												[T -> upload(String-String-String-String-File-File) : MethodDecl "public Upload upload(final String bucketName, final String key, final File file)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, file));     }" compose:Replacement merge: LineBased]
												[T -> upload(PutObjectRequest-PutObjectRequest) : MethodDecl "public Upload upload(final PutObjectRequest putObjectRequest)         throws AmazonServiceException, AmazonClientException {         return upload(putObjectRequest, null);     }" compose:Replacement merge: LineBased]
												[T -> upload(PutObjectRequest-PutObjectRequest-TransferStateChangeListener-TransferStateChangeListener) : MethodDecl "private Upload upload(final PutObjectRequest putObjectRequest, final TransferStateChangeListener stateListener)             throws AmazonServiceException, AmazonClientException {              appendUserAgent(putObjectRequest, USER_AGENT);              if (putObjectRequest.getMetadata() == null)                 putObjectRequest.setMetadata(new ObjectMetadata());             ObjectMetadata metadata = putObjectRequest.getMetadata();              if ( TransferManagerUtils.getRequestFile(putObjectRequest) != null ) {                 File file = TransferManagerUtils.getRequestFile(putObjectRequest);                  // Always set the content length, even if it's already set                 metadata.setContentLength(file.length());                  // Only set the content type if it hasn't already been set                 if ( metadata.getContentType() == null ) {                     metadata.setContentType(Mimetypes.getInstance().getMimetype(file));                 }             }              String description = "Uploading to " + putObjectRequest.getBucketName() + "/" + putObjectRequest.getKey();             TransferProgressImpl transferProgress = new TransferProgressImpl();             transferProgress.setTotalBytesToTransfer(TransferManagerUtils.getContentLength(putObjectRequest));              ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                     transferProgress), putObjectRequest.getProgressListener());             putObjectRequest.setProgressListener(listenerChain);              UploadImpl upload = new UploadImpl(description, transferProgress, listenerChain, stateListener);              UploadCallable uploadCallable = new UploadCallable(this, threadPool, upload, putObjectRequest, listenerChain);             UploadMonitor watcher = new UploadMonitor(this, upload, threadPool, uploadCallable, putObjectRequest, listenerChain);             watcher.setTimedThreadPool(timedThreadPool);             upload.setMonitor(watcher);              return upload;         }" compose:Replacement merge: LineBased]
												[T -> download(String-String-String-String-File-File) : MethodDecl "public Download download(String bucket, String key, File file) {         return download(new GetObjectRequest(bucket, key), file);     }" compose:Replacement merge: LineBased]
												[T -> download(GetObjectRequest-GetObjectRequest-File-File) : MethodDecl "public Download download(final GetObjectRequest getObjectRequest, final File file) {         return download(getObjectRequest, file, null);     }" compose:Replacement merge: LineBased]
												[T -> download(GetObjectRequest-GetObjectRequest-File-File-TransferStateChangeListener-TransferStateChangeListener) : MethodDecl "private Download download(final GetObjectRequest getObjectRequest,                               final File file,                               final TransferStateChangeListener stateListener) {          appendUserAgent(getObjectRequest, USER_AGENT);          String description = "Downloading from " + getObjectRequest.getBucketName() + "/" + getObjectRequest.getKey();          // Add our own transfer progress listener         TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                 transferProgress), getObjectRequest.getProgressListener());         getObjectRequest.setProgressListener(listenerChain);         final ObjectMetadata objectMetadata = s3.getObjectMetadata(getObjectRequest.getBucketName(), getObjectRequest.getKey());          final StartDownloadLock startDownloadLock = new StartDownloadLock();         final DownloadImpl download = new DownloadImpl(description, transferProgress, listenerChain, null, stateListener);         long contentLength = objectMetadata.getContentLength();         if (getObjectRequest.getRange() != null && getObjectRequest.getRange().length == 2) {             long startingByte = getObjectRequest.getRange()[0];             long lastByte     = getObjectRequest.getRange()[1];             contentLength     = lastByte - startingByte;         }          transferProgress.setTotalBytesToTransfer(contentLength);          Future<?> future = threadPool.submit(new Callable<Object>() {             @Override             public Object call() throws Exception {                 try {                     synchronized (startDownloadLock) {                         if ( !startDownloadLock.downloadReady ) {                                 try {                                     startDownloadLock.wait();                                     } catch ( InterruptedException e ) {                                  throw new AmazonClientException("Couldn't wait for setting future into the monitor");                              }                          }                      }                     download.setState(TransferState.InProgress);                     S3Object s3Object = ServiceUtils.retryableDownloadS3ObjectToFile(file, new ServiceUtils.RetryableS3DownloadTask() {              @Override       public S3Object getS3ObjectStream() {        S3Object s3Object = s3.getObject(getObjectRequest);        download.setS3Object(s3Object);        return s3Object;       }              @Override       public boolean needIntegrityCheck() {                       // Don't perform the integrity check if the stream data is wrapped                       // in a decryption stream, or if we're only looking at a range of                       // the data, since otherwise the checksum won't match up.                       boolean performIntegrityCheck = true;                       if (getObjectRequest.getRange() != null) performIntegrityCheck = false;                       if (s3 instanceof AmazonS3EncryptionClient) performIntegrityCheck = false;                       return performIntegrityCheck;           }      });                                           if (s3Object == null) {                         download.setState(TransferState.Canceled);                         download.setMonitor(new DownloadMonitor(download, null));                         return download;                     }                       download.setState(TransferState.Completed);                     return true;                 } catch (Exception e) {                     // Downloads aren't allowed to move from canceled to failed                     if (download.getState() != TransferState.Canceled) {                         download.setState(TransferState.Failed);                     }                     throw e;                 }             }         });         download.setMonitor(new DownloadMonitor(download, future));         synchronized (startDownloadLock) {             startDownloadLock.downloadReady = true;             startDownloadLock.notify();         }         return download;     }" compose:Replacement merge: LineBased]
												[T -> downloadDirectory(String-String-String-String-File-File) : MethodDecl "public MultipleFileDownload downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory) {          if ( keyPrefix == null )             keyPrefix = "";          List<S3ObjectSummary> objectSummaries = new LinkedList<S3ObjectSummary>();         Stack<String> commonPrefixes = new Stack<String>();         commonPrefixes.add(keyPrefix);         long totalSize = 0;          // Recurse all virtual subdirectories to get a list of object summaries.         // This is a depth-first search.         do {             String prefix = commonPrefixes.pop();             ObjectListing listObjectsResponse = null;              do {                 if ( listObjectsResponse == null ) {                     ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName)                             .withDelimiter(DEFAULT_DELIMITER).withPrefix(prefix);                     listObjectsResponse = s3.listObjects(listObjectsRequest);                 } else {                     listObjectsResponse = s3.listNextBatchOfObjects(listObjectsResponse);                 }                  for ( S3ObjectSummary s : listObjectsResponse.getObjectSummaries() ) {                     // Skip any files that are also virtual directories, since                     // we can't save both a directory and a file of the same                     // name.                     if ( !s.getKey().equals(prefix)                             && !listObjectsResponse.getCommonPrefixes().contains(s.getKey() + DEFAULT_DELIMITER) ) {                         objectSummaries.add(s);                         totalSize += s.getSize();                     } else {                         log.debug("Skipping download for object " + s.getKey()                                 + " since it is also a virtual directory");                     }                 }                  commonPrefixes.addAll(listObjectsResponse.getCommonPrefixes());             } while ( listObjectsResponse.isTruncated() );         } while ( !commonPrefixes.isEmpty() );          TransferProgressImpl transferProgress = new TransferProgressImpl();         transferProgress.setTotalBytesToTransfer(totalSize);         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<DownloadImpl> downloads = new ArrayList<DownloadImpl>();          String description = "Downloading from " + bucketName + "/" + keyPrefix;         final MultipleFileDownloadImpl multipleFileDownload = new MultipleFileDownloadImpl(description, transferProgress,                 new ProgressListenerChain(listener), keyPrefix, bucketName, downloads);         multipleFileDownload.setMonitor(new MultipleFileTransferMonitor(multipleFileDownload, downloads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileDownload);          for ( S3ObjectSummary summary : objectSummaries ) {             // TODO: non-standard delimiters             File f = new File(destinationDirectory, summary.getKey());             File parentFile = f.getParentFile();             if ( !parentFile.exists() && !parentFile.mkdirs() ) {                 throw new RuntimeException("Couldn't create parent directories for " + f.getAbsolutePath());             }              downloads.add((DownloadImpl) download(                     new GetObjectRequest(summary.getBucketName(), summary.getKey()).withProgressListener(listener), f,                     stateChangeListener));         }          if ( downloads.isEmpty() ) {             multipleFileDownload.setState(TransferState.Completed);             return multipleFileDownload;         }          // Notify all state changes waiting for the downloads to all be queued         // to wake up and continue.         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileDownload;     }" compose:Replacement merge: LineBased]
												[NT -> AllDownloadsQueuedLock : InnerClassDecl]
													[T -> - : Modifiers "private static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> AllDownloadsQueuedLock : Id "AllDownloadsQueuedLock" compose:Replacement merge: Default]
													[T -> allQueued : FieldDecl "private volatile boolean allQueued = false;" compose:Replacement merge: SemanticConflict]
												[NT -> StartDownloadLock : InnerClassDecl]
													[T -> - : Modifiers "private  static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> StartDownloadLock : Id "StartDownloadLock" compose:Replacement merge: Default]
													[T -> downloadReady : FieldDecl "private volatile boolean downloadReady = false;" compose:Replacement merge: SemanticConflict]
												[NT -> MultipleFileTransferStateChangeListener : InnerClassDecl]
													[T -> - : Modifiers "private static final" compose:Replacement merge: SemanticConflict]
													[T -> - : ClassOrInterface1 "class" compose:Replacement merge: Default]
													[T -> MultipleFileTransferStateChangeListener : Id "MultipleFileTransferStateChangeListener" compose:Replacement merge: Default]
													[T -> ImplList : ImplementsList "implements TransferStateChangeListener" compose:Replacement merge: SemanticConflict]
													[T -> allTransfersQueuedLock : FieldDecl "private final AllDownloadsQueuedLock allTransfersQueuedLock;" compose:Replacement merge: SemanticConflict]
													[T -> multipleFileTransfer : FieldDecl "private final MultipleFileTransfer multipleFileTransfer;" compose:Replacement merge: SemanticConflict]
													[T -> MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock-AllDownloadsQueuedLock-MultipleFileTransfer-MultipleFileTransfer) : ConstructorDecl "public MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock allTransfersQueuedLock,                 MultipleFileTransfer multipleFileDownload) {             this.allTransfersQueuedLock = allTransfersQueuedLock;             this.multipleFileTransfer = multipleFileDownload;         }" compose:Replacement merge: LineBased]
													[T -> transferStateChanged(Transfer-Transfer-TransferState-TransferState) : MethodDecl "@Override         public void transferStateChanged(Transfer upload, TransferState state) {              // There's a race here: we can't start monitoring the state of             // individual transfers until we have added all the transfers to the             // list, or we may incorrectly report completion.             synchronized (allTransfersQueuedLock) {                 if ( !allTransfersQueuedLock.allQueued ) {                     try {                         allTransfersQueuedLock.wait();                     } catch ( InterruptedException e ) {                         throw new AmazonClientException("Couldn't wait for all downloads to be queued");                     }                 }             }              synchronized (multipleFileTransfer) {                 if ( multipleFileTransfer.getState() == state || multipleFileTransfer.isDone() )                     return;                  /*                  * If we're not already in a terminal state, allow a transition                  * to a non-waiting state. Mark completed if this download is                  * completed and the monitor says all of the rest are as well.                  */                 if ( state == TransferState.InProgress ) {                     multipleFileTransfer.setState(state);                 } else if ( multipleFileTransfer.getMonitor().isDone() ) {                     multipleFileTransfer.collateFinalState();                 } else {                     multipleFileTransfer.setState(TransferState.InProgress);                 }             }         }" compose:Replacement merge: LineBased]
												[T -> auto3 : EmptyDecl ";" compose:Replacement merge: Default]
												[T -> uploadDirectory(String-String-String-String-File-File-boolean-boolean) : MethodDecl "public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories) {      return uploadDirectory(bucketName, virtualDirectoryKeyPrefix, directory, includeSubdirectories, null);     }" compose:Replacement merge: LineBased]
												[T -> uploadDirectory(String-String-String-String-File-File-boolean-boolean-ObjectMetadataProvider-ObjectMetadataProvider) : MethodDecl "public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories, ObjectMetadataProvider metadataProvider) {      if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a directory to upload");         }          List<File> files = new LinkedList<File>();         listFiles(directory, files, includeSubdirectories);                  return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, metadataProvider);     }" compose:Replacement merge: LineBased]
												[T -> uploadFileList(String-String-String-String-File-File-List<File>-List<File>) : MethodDecl "public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files) {           return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, null);     }" compose:Replacement merge: LineBased]
												[T -> uploadFileList(String-String-String-String-File-File-List<File>-List<File>-ObjectMetadataProvider-ObjectMetadataProvider) : MethodDecl "public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files,ObjectMetadataProvider metadataProvider) {          if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a common base directory for uploaded files");         }          if (virtualDirectoryKeyPrefix == null || virtualDirectoryKeyPrefix.length() == 0) {             virtualDirectoryKeyPrefix = "";         } else if ( !virtualDirectoryKeyPrefix.endsWith("/") ) {             virtualDirectoryKeyPrefix = virtualDirectoryKeyPrefix + "/";         }          TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<UploadImpl> uploads = new LinkedList<UploadImpl>();         MultipleFileUploadImpl multipleFileUpload = new MultipleFileUploadImpl("Uploading etc", transferProgress, null, virtualDirectoryKeyPrefix, bucketName, uploads);         multipleFileUpload.setMonitor(new MultipleFileTransferMonitor(multipleFileUpload, uploads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileUpload);          if ( files == null || files.isEmpty()) {             multipleFileUpload.setState(TransferState.Completed);         }          long totalSize = 0;         for (File f : files) {             //Check, if file, since only files can be uploaded.             if (f.isFile()) {                 totalSize += f.length();                 String key = f.getAbsolutePath().substring(directory.getAbsolutePath().length() + 1)                         .replaceAll("\\\\", "/");                                  ObjectMetadata metadata=new ObjectMetadata();                                  // Invoke the callback if it's present.                 // The callback allows the user to customize the metadata for each file being uploaded.                 if(metadataProvider!=null){                    metadataProvider.provideObjectMetadata(f,metadata);                 }                                  uploads.add((UploadImpl) upload(                         new PutObjectRequest(bucketName, virtualDirectoryKeyPrefix + key, f).withMetadata(metadata).withProgressListener(listener),                         stateChangeListener));             }         }          transferProgress.setTotalBytesToTransfer(totalSize);          // Notify all state changes waiting for the uploads to all be queued         // to wake up and continue         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileUpload;     }" compose:Replacement merge: LineBased]
												[T -> listFiles(File-File-List<File>-List<File>-boolean-boolean) : MethodDecl "private void listFiles(File dir, List<File> results, boolean includeSubDirectories) {         File[] found = dir.listFiles();         if ( found != null ) {             for ( File f : found ) {                 if (f.isDirectory()) {                     if (includeSubDirectories) {                         listFiles(f, results, includeSubDirectories);                     }                 } else {                     results.add(f);                 }             }         }     }" compose:Replacement merge: LineBased]
												[T -> abortMultipartUploads(String-String-Date-Date) : MethodDecl "public void abortMultipartUploads(String bucketName, Date date)             throws AmazonServiceException, AmazonClientException {         MultipartUploadListing uploadListing = s3.listMultipartUploads(appendUserAgent(                 new ListMultipartUploadsRequest(bucketName), USER_AGENT));         do {             for (MultipartUpload upload : uploadListing.getMultipartUploads()) {                 if (upload.getInitiated().compareTo(date) < 0) {                     s3.abortMultipartUpload(appendUserAgent(new AbortMultipartUploadRequest(                             bucketName, upload.getKey(), upload.getUploadId()), USER_AGENT));                 }             }              ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName)                 .withUploadIdMarker(uploadListing.getNextUploadIdMarker())                 .withKeyMarker(uploadListing.getNextKeyMarker());             uploadListing = s3.listMultipartUploads(appendUserAgent(request, USER_AGENT));         } while (uploadListing.isTruncated());     }" compose:Replacement merge: LineBased]
												[T -> shutdownNow({FormalParametersInternal}) : MethodDecl "public void shutdownNow() {         threadPool.shutdownNow();         timedThreadPool.shutdownNow();          if (s3 instanceof AmazonS3Client) {             ((AmazonS3Client)s3).shutdown();         }     }" compose:Replacement merge: LineBased]
												[T -> appendUserAgent(X-X-String-String) : MethodDecl "public <X extends AmazonWebServiceRequest> X appendUserAgent(X request, String userAgent) {         request.getRequestClientOptions().addClientMarker(USER_AGENT);         return request;     }" compose:Replacement merge: LineBased]
												[T -> USER_AGENT : FieldDecl "private static final String USER_AGENT = TransferManager.class.getName() + "/" + VersionInfoUtils.getVersion();" compose:Replacement merge: SemanticConflict]
												[T -> DEFAULT_DELIMITER : FieldDecl "private static final String DEFAULT_DELIMITER = "/";" compose:Replacement merge: SemanticConflict]
												[T -> daemonThreadFactory : FieldDecl "private static final ThreadFactory daemonThreadFactory = new ThreadFactory() {         final AtomicInteger threadCount = new AtomicInteger( 0 );         public Thread newThread(Runnable r) {             int threadNumber = threadCount.incrementAndGet();             Thread thread = new Thread(r);             thread.setDaemon(true);             thread.setName("S3TransferManagerTimedThread-" + threadNumber);             return thread;         }     };" compose:Replacement merge: SemanticConflict]
[NT -> left : Feature]
	[NT -> src : Folder]
		[NT -> main : Folder]
			[NT -> java : Folder]
				[NT -> com : Folder]
					[NT -> amazonaws : Folder]
						[NT -> services : Folder]
							[NT -> s3 : Folder]
								[NT -> transfer : Folder]
									[NT -> TransferManager.java.merge : .java.merge-File]
										[T -> TransferManager.java : .java-Content "/*  * Copyright 2010-2013 Amazon.com, Inc. or its affiliates. All Rights Reserved.  *  * Licensed under the Apache License, Version 2.0 (the "License").  * You may not use this file except in compliance with the License.  * A copy of the License is located at  *  *  http://aws.amazon.com/apache2.0  *  * or in the "license" file accompanying this file. This file is distributed  * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either  * express or implied. See the License for the specific language governing  * permissions and limitations under the License.  */ package com.amazonaws.services.s3.transfer;  import java.io.File; import java.io.InputStream; import java.util.ArrayList; import java.util.Date; import java.util.LinkedList; import java.util.List; import java.util.Stack; import java.util.concurrent.Callable; import java.util.concurrent.Future; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.ScheduledThreadPoolExecutor; import java.util.concurrent.ThreadPoolExecutor;  import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory;  import com.amazonaws.AmazonClientException; import com.amazonaws.AmazonServiceException; import com.amazonaws.AmazonWebServiceRequest; import com.amazonaws.auth.AWSCredentials; import com.amazonaws.event.ProgressListener; import com.amazonaws.event.ProgressListenerChain; import com.amazonaws.services.s3.AmazonS3; import com.amazonaws.services.s3.AmazonS3Client; import com.amazonaws.services.s3.AmazonS3EncryptionClient; import com.amazonaws.services.s3.internal.Mimetypes; import com.amazonaws.services.s3.internal.ServiceUtils; import com.amazonaws.services.s3.model.AbortMultipartUploadRequest; import com.amazonaws.services.s3.model.GetObjectRequest; import com.amazonaws.services.s3.model.ListMultipartUploadsRequest; import com.amazonaws.services.s3.model.ListObjectsRequest; import com.amazonaws.services.s3.model.MultipartUpload; import com.amazonaws.services.s3.model.MultipartUploadListing; import com.amazonaws.services.s3.model.ObjectListing; import com.amazonaws.services.s3.model.ObjectMetadata; import com.amazonaws.services.s3.model.PutObjectRequest; import com.amazonaws.services.s3.model.S3Object; import com.amazonaws.services.s3.model.S3ObjectSummary; import com.amazonaws.services.s3.transfer.Transfer.TransferState; import com.amazonaws.services.s3.transfer.internal.DownloadImpl; import com.amazonaws.services.s3.transfer.internal.DownloadMonitor; import com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl; import com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer; import com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor; import com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl; import com.amazonaws.services.s3.transfer.internal.TransferManagerUtils; import com.amazonaws.services.s3.transfer.internal.TransferProgressImpl; import com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener; import com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener; import com.amazonaws.services.s3.transfer.internal.UploadCallable; import com.amazonaws.services.s3.transfer.internal.UploadImpl; import com.amazonaws.services.s3.transfer.internal.UploadMonitor; import com.amazonaws.util.VersionInfoUtils;  /**  * High level utility for managing transfers to Amazon S3.  * <p>  * <code>TransferManager</code> provides a simple API for uploading content to  * Amazon S3, and makes extensive use of Amazon S3 multipart uploads to achieve  * enhanced throughput, performance and reliability.  * <p>  * When possible, <code>TransferManager</code> attempts to use multiple threads  * to upload multiple parts of a single upload at once. When dealing with large  * content sizes and high bandwidth, this can have a significant increase on  * throughput.  * <p>  * <code>TransferManager</code> is responsible for managing resources such as  * connections and threads; share a single instance of  * <code>TransferManager</code> whenever possible. <code>TransferManager</code>,  * like all the client classes in the AWS SDK for Java, is thread safe.  * <p>  * Using <code>TransferManager</code> to upload options to Amazon S3 is easy:  *  * <pre>  * AWSCredentials myCredentials = new BasicAWSCredentials(...);  * TransferManager tx = new TransferManager(myCredentials);  * Upload myUpload = tx.upload(myBucket, myFile.getName(), myFile);  *  * // You can poll your transfer's status to check its progress  * if (myUpload.isDone() == false) {  *     System.out.println("Transfer: " + myUpload.getDescription());  *     System.out.println("  - State: " + myUpload.getState());  *     System.out.println("  - Progress: " + myUpload.getProgress().getBytesTransferred());  * }  *  * // Transfers also allow you to set a <code>ProgressListener</code> to receive  * // asynchronous notifications about your transfer's progress.  * myUpload.addProgressListener(myProgressListener);  *  * // Or you can block the current thread and wait for your transfer to  * // to complete.  If the transfer fails, this method will throw an  * // AmazonClientException or AmazonServiceException detailing the reason.  * myUpload.waitForCompletion();  * </pre>  * <p>  * Note: Transfers are stored in memory. If the JVM is restarted, previous  * transfers are no longer accessible. If needed, clean up any multipart uploads  * that are incomplete.  */ public class TransferManager {      /** The low level client we use to make the actual calls to Amazon S3. */     private AmazonS3 s3;      /** Configuration for how TransferManager processes requests. */     private TransferManagerConfiguration configuration;     /** The thread pool in which transfers are uploaded or downloaded. */     private ThreadPoolExecutor threadPool;      /** Thread used for periodicially checking transfers and updating thier state. */     private ScheduledExecutorService timedThreadPool = new ScheduledThreadPoolExecutor(1);      private static final Log log = LogFactory.getLog(TransferManager.class);       /**      * Constructs a new <code>TransferManager</code> and Amazon S3 client using      * the specified AWS security credentials.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      *      * @param credentials      *            The AWS security credentials to use when making authenticated      *            requests.      */     public TransferManager(AWSCredentials credentials) {         this(new AmazonS3Client(credentials));     }      /**      * Constructs a new <code>TransferManager</code>,      * specifying the client to use when making      * requests to Amazon S3.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      * </p>      *      * @param s3      *            The client to use when making requests to Amazon S3.      */     public TransferManager(AmazonS3 s3) {         this(s3, TransferManagerUtils.createDefaultExecutorService());     }      /**      * Constructs a new <code>TransferManager</code>      * specifying the client and thread pool to use when making      * requests to Amazon S3.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      *      * @param s3      *            The client to use when making requests to Amazon S3.      * @param threadPool      *            The thread pool in which to execute requests.      */     public TransferManager(AmazonS3 s3, ThreadPoolExecutor threadPool) {         this.s3 = s3;         this.threadPool = threadPool;         this.configuration = new TransferManagerConfiguration();     }       /**      * Sets the configuration which specifies how      * this <code>TransferManager</code> processes requests.      *      * @param configuration      *            The new configuration specifying how      *            this <code>TransferManager</code>      *            processes requests.      */     public void setConfiguration(TransferManagerConfiguration configuration) {         this.configuration = configuration;     }      /**      * Returns the configuration which specifies how      * this <code>TransferManager</code> processes requests.      *      * @return The configuration settings for this <code>TransferManager</code>.      */     public TransferManagerConfiguration getConfiguration() {         return configuration;     }      /**      * Returns the underlying Amazon S3 client used to make requests to      * Amazon S3.      *      * @return The underlying Amazon S3 client used to make requests to      *         Amazon S3.      */     public AmazonS3 getAmazonS3Client() {         return s3;     }      /**      * <p>      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * </p>      * <p>      * When uploading options from a stream, callers <b>must</b> supply the size of      * options in the stream through the content length field in the      * <code>ObjectMetadata</code> parameter.      * If no content length is specified for the input      * stream, then TransferManager will attempt to buffer all the stream      * contents in memory and upload the options as a traditional, single part      * upload. Because the entire stream contents must be buffered in memory,      * this can be very expensive, and should be avoided whenever possible.      * </p>      * <p>      * Use the returned <code>Upload</code> object to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * </p>      * <p>      * If resources are available, the upload will begin immediately.      * Otherwise, the upload is scheduled and started as soon as      * resources become available.      * </p>      *      * @param bucketName      *            The name of the bucket to upload the new object to.      * @param key      *            The key in the specified bucket by which to store the new      *            object.      * @param input      *            The input stream containing the options to upload to Amazon S3.      * @param objectMetadata      *            Additional information about the object being uploaded,      *            including the size of the options, content type, additional      *            custom user metadata, etc.      *      * @return A new <code>Upload</code> object to use to check      *      the state of the upload, listen for progress notifications,      *      and otherwise manage the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final String bucketName, final String key, final InputStream input, ObjectMetadata objectMetadata)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, input, objectMetadata));     }      /**      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * <p>      * The returned Upload object allows you to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * <p>      * If resources are available, the upload will begin immediately, otherwise      * it will be scheduled and started as soon as resources become available.      *      * @param bucketName      *            The name of the bucket to upload the new object to.      * @param key      *            The key in the specified bucket by which to store the new      *            object.      * @param file      *            The file to upload.      *      * @return A new Upload object which can be used to check state of the      *         upload, listen for progress notifications, and otherwise manage      *         the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final String bucketName, final String key, final File file)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, file));     }      /**      * <p>      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * </p>      * <p>      * Use the returned <code>Upload</code> object to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * </p>      * <p>      * If resources are available, the upload will begin immediately.      * Otherwise, the upload is scheduled and started as soon as      * resources become available.      * </p>      *      * @param putObjectRequest      *            The request containing all the parameters for the upload.      *      * @return A new <code>Upload</code> object to use to check      *      the state of the upload, listen for progress notifications,      *      and otherwise manage the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final PutObjectRequest putObjectRequest)         throws AmazonServiceException, AmazonClientException {         return upload(putObjectRequest, null);     }      /**      * Same as public version of upload, but attaches a      * {@link TransferStateChangeListener} to the upload object so that it can be      * monitored.      */     private Upload upload(final PutObjectRequest putObjectRequest, final TransferStateChangeListener stateListener)             throws AmazonServiceException, AmazonClientException {              appendUserAgent(putObjectRequest, USER_AGENT);              if (putObjectRequest.getMetadata() == null)                 putObjectRequest.setMetadata(new ObjectMetadata());             ObjectMetadata metadata = putObjectRequest.getMetadata();              if ( TransferManagerUtils.getRequestFile(putObjectRequest) != null ) {                 File file = TransferManagerUtils.getRequestFile(putObjectRequest);                  // Always set the content length, even if it's already set                 metadata.setContentLength(file.length());                  // Only set the content type if it hasn't already been set                 if ( metadata.getContentType() == null ) {                     metadata.setContentType(Mimetypes.getInstance().getMimetype(file));                 }             }              String description = "Uploading to " + putObjectRequest.getBucketName() + "/" + putObjectRequest.getKey();             TransferProgressImpl transferProgress = new TransferProgressImpl();             transferProgress.setTotalBytesToTransfer(TransferManagerUtils.getContentLength(putObjectRequest));              ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                     transferProgress), putObjectRequest.getGeneralProgressListener());             putObjectRequest.setGeneralProgressListener(listenerChain);              UploadImpl upload = new UploadImpl(description, transferProgress, listenerChain, stateListener);              UploadCallable uploadCallable = new UploadCallable(this, threadPool, upload, putObjectRequest, listenerChain);             UploadMonitor watcher = new UploadMonitor(this, upload, threadPool, uploadCallable, putObjectRequest, listenerChain);             watcher.setTimedThreadPool(timedThreadPool);             upload.setMonitor(watcher);              return upload;         }       /**      * Schedules a new transfer to download data from Amazon S3 and save it to      * the specified file. This method is non-blocking and returns immediately      * (i.e. before the data has been fully downloaded).      * <p>      * Use the returned Download object to query the progress of the transfer,      * add listeners for progress events, and wait for the download to complete.      *      * @param bucket      *            The name of the bucket containing the object to download.      * @param key      *            The key under which the object to download is stored.      * @param file      *            The file to download the object's data to.      *      * @return A new <code>Download</code> object to use to check the state of      *         the download, listen for progress notifications, and otherwise      *         manage the download.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Download download(String bucket, String key, File file) {         return download(new GetObjectRequest(bucket, key), file);     }      /**      * Schedules a new transfer to download data from Amazon S3 and save it to      * the specified file. This method is non-blocking and returns immediately      * (i.e. before the data has been fully downloaded).      * <p>      * Use the returned Download object to query the progress of the transfer,      * add listeners for progress events, and wait for the download to complete.      *      * @param getObjectRequest      *            The request containing all the parameters for the download.      * @param file      *            The file to download the object data to.      *      * @return A new <code>Download</code> object to use to check the state of      *         the download, listen for progress notifications, and otherwise      *         manage the download.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Download download(final GetObjectRequest getObjectRequest, final File file) {         return download(getObjectRequest, file, null);     }      /**      * Same as public interface, but adds a state listener so that callers can      * be notified of state changes to the download.      *      * @see TransferManager#download(GetObjectRequest, File)      */     private Download download(final GetObjectRequest getObjectRequest,                               final File file,                               final TransferStateChangeListener stateListener) {          appendUserAgent(getObjectRequest, USER_AGENT);          String description = "Downloading from " + getObjectRequest.getBucketName() + "/" + getObjectRequest.getKey();          // Add our own transfer progress listener         TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                 transferProgress), getObjectRequest.getGeneralProgressListener());         getObjectRequest.setGeneralProgressListener(listenerChain);         final ObjectMetadata objectMetadata = s3.getObjectMetadata(getObjectRequest.getBucketName(), getObjectRequest.getKey());          final StartDownloadLock startDownloadLock = new StartDownloadLock();         final DownloadImpl download = new DownloadImpl(description, transferProgress, listenerChain, null, stateListener);         long contentLength = objectMetadata.getContentLength();         if (getObjectRequest.getRange() != null && getObjectRequest.getRange().length == 2) {             long startingByte = getObjectRequest.getRange()[0];             long lastByte     = getObjectRequest.getRange()[1];             contentLength     = lastByte - startingByte;         }          transferProgress.setTotalBytesToTransfer(contentLength);          Future<?> future = threadPool.submit(new Callable<Object>() {             @Override             public Object call() throws Exception {                 try {                     synchronized (startDownloadLock) {                         if ( !startDownloadLock.downloadReady ) {                                 try {                                     startDownloadLock.wait();                                     } catch ( InterruptedException e ) {                                  throw new AmazonClientException("Couldn't wait for setting future into the monitor");                              }                          }                      }                     download.setState(TransferState.InProgress);                     S3Object s3Object = ServiceUtils.retryableDownloadS3ObjectToFile(file, new ServiceUtils.RetryableS3DownloadTask() {                                                  @Override                         public S3Object getS3ObjectStream() {                             S3Object s3Object = s3.getObject(getObjectRequest);                             download.setS3Object(s3Object);                             return s3Object;                         }                                                  @Override                         public boolean needIntegrityCheck() {                             // Don't perform the integrity check if the stream data is wrapped                             // in a decryption stream, or if we're only looking at a range of                             // the data, since otherwise the checksum won't match up.                             boolean performIntegrityCheck = true;                             if (getObjectRequest.getRange() != null) performIntegrityCheck = false;                             if (s3 instanceof AmazonS3EncryptionClient) performIntegrityCheck = false;                             return performIntegrityCheck;                         }                     });                                           if (s3Object == null) {                         download.setState(TransferState.Canceled);                         download.setMonitor(new DownloadMonitor(download, null));                         return download;                     }                       download.setState(TransferState.Completed);                     return true;                 } catch (Exception e) {                     // Downloads aren't allowed to move from canceled to failed                     if (download.getState() != TransferState.Canceled) {                         download.setState(TransferState.Failed);                     }                     throw e;                 }             }         });         download.setMonitor(new DownloadMonitor(download, future));         synchronized (startDownloadLock) {             startDownloadLock.downloadReady = true;             startDownloadLock.notify();         }         return download;     }      /**      * Downloads all objects in the virtual directory designated by the      * keyPrefix given to the destination directory given. All virtual      * subdirectories will be downloaded recursively.      *      * @param bucketName      *            The bucket containing the virtual directory      * @param keyPrefix      *            The key prefix for the virtual directory, or null for the      *            entire bucket. All subdirectories will be downloaded      *            recursively.      * @param destinationDirectory      *            The directory to place downloaded files. Subdirectories will      *            be created as necessary.      */     public MultipleFileDownload downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory) {          if ( keyPrefix == null )             keyPrefix = "";          List<S3ObjectSummary> objectSummaries = new LinkedList<S3ObjectSummary>();         Stack<String> commonPrefixes = new Stack<String>();         commonPrefixes.add(keyPrefix);         long totalSize = 0;          // Recurse all virtual subdirectories to get a list of object summaries.         // This is a depth-first search.         do {             String prefix = commonPrefixes.pop();             ObjectListing listObjectsResponse = null;              do {                 if ( listObjectsResponse == null ) {                     ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName)                             .withDelimiter(DEFAULT_DELIMITER).withPrefix(prefix);                     listObjectsResponse = s3.listObjects(listObjectsRequest);                 } else {                     listObjectsResponse = s3.listNextBatchOfObjects(listObjectsResponse);                 }                  for ( S3ObjectSummary s : listObjectsResponse.getObjectSummaries() ) {                     // Skip any files that are also virtual directories, since                     // we can't save both a directory and a file of the same                     // name.                     if ( !s.getKey().equals(prefix)                             && !listObjectsResponse.getCommonPrefixes().contains(s.getKey() + DEFAULT_DELIMITER) ) {                         objectSummaries.add(s);                         totalSize += s.getSize();                     } else {                         log.debug("Skipping download for object " + s.getKey()                                 + " since it is also a virtual directory");                     }                 }                  commonPrefixes.addAll(listObjectsResponse.getCommonPrefixes());             } while ( listObjectsResponse.isTruncated() );         } while ( !commonPrefixes.isEmpty() );          TransferProgressImpl transferProgress = new TransferProgressImpl();         transferProgress.setTotalBytesToTransfer(totalSize);         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<DownloadImpl> downloads = new ArrayList<DownloadImpl>();          String description = "Downloading from " + bucketName + "/" + keyPrefix;         final MultipleFileDownloadImpl multipleFileDownload = new MultipleFileDownloadImpl(description, transferProgress,                 new ProgressListenerChain(listener), keyPrefix, bucketName, downloads);         multipleFileDownload.setMonitor(new MultipleFileTransferMonitor(multipleFileDownload, downloads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileDownload);          for ( S3ObjectSummary summary : objectSummaries ) {             // TODO: non-standard delimiters             File f = new File(destinationDirectory, summary.getKey());             File parentFile = f.getParentFile();             if ( !parentFile.exists() && !parentFile.mkdirs() ) {                 throw new RuntimeException("Couldn't create parent directories for " + f.getAbsolutePath());             }              downloads.add((DownloadImpl) download(                     new GetObjectRequest(summary.getBucketName(), summary.getKey()).withGeneralProgressListener(listener), f,                     stateChangeListener));         }          if ( downloads.isEmpty() ) {             multipleFileDownload.setState(TransferState.Completed);             return multipleFileDownload;         }          // Notify all state changes waiting for the downloads to all be queued         // to wake up and continue.         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileDownload;     }      private static final class AllDownloadsQueuedLock {         private volatile boolean allQueued = false;     }      private  static final class StartDownloadLock {         private volatile boolean downloadReady = false;     }      private static final class MultipleFileTransferStateChangeListener implements TransferStateChangeListener {          private final AllDownloadsQueuedLock allTransfersQueuedLock;         private final MultipleFileTransfer multipleFileTransfer;          public MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock allTransfersQueuedLock,                 MultipleFileTransfer multipleFileDownload) {             this.allTransfersQueuedLock = allTransfersQueuedLock;             this.multipleFileTransfer = multipleFileDownload;         }          @Override         public void transferStateChanged(Transfer upload, TransferState state) {              // There's a race here: we can't start monitoring the state of             // individual transfers until we have added all the transfers to the             // list, or we may incorrectly report completion.             synchronized (allTransfersQueuedLock) {                 if ( !allTransfersQueuedLock.allQueued ) {                     try {                         allTransfersQueuedLock.wait();                     } catch ( InterruptedException e ) {                         throw new AmazonClientException("Couldn't wait for all downloads to be queued");                     }                 }             }              synchronized (multipleFileTransfer) {                 if ( multipleFileTransfer.getState() == state || multipleFileTransfer.isDone() )                     return;                  /*                  * If we're not already in a terminal state, allow a transition                  * to a non-waiting state. Mark completed if this download is                  * completed and the monitor says all of the rest are as well.                  */                 if ( state == TransferState.InProgress ) {                     multipleFileTransfer.setState(state);                 } else if ( multipleFileTransfer.getMonitor().isDone() ) {                     multipleFileTransfer.collateFinalState();                 } else {                     multipleFileTransfer.setState(TransferState.InProgress);                 }             }         }     };      /**      * Uploads all files in the directory given to the bucket named, optionally      * recursing for all subdirectories.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The directory to upload.      * @param includeSubdirectories      *            Whether to include subdirectories in the upload. If true,      *            files found in subdirectories will be included with an      *            appropriate concatenation to the key prefix.      */     public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories) {      return uploadDirectory(bucketName, virtualDirectoryKeyPrefix, directory, includeSubdirectories, null);     }          /**      * Uploads all files in the directory given to the bucket named, optionally      * recursing for all subdirectories.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The directory to upload.                        * @param includeSubdirectories      *            Whether to include subdirectories in the upload. If true,      *            files found in subdirectories will be included with an      *            appropriate concatenation to the key prefix.      * @param metadataProvider      *      A callback of type <code>ObjectMetadataProvider</code> which       *            is used to provide metadata for each file being uploaded.      */     public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories, ObjectMetadataProvider metadataProvider) {      if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a directory to upload");         }          List<File> files = new LinkedList<File>();         listFiles(directory, files, includeSubdirectories);                  return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, metadataProvider);     }          /**      * Uploads all specified files to the bucket named, constructing      * relative keys depending on the commonParentDirectory given.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The common parent directory of files to upload. The keys      *            of the files in the list of files are constructed relative to      *            this directory and the virtualDirectoryKeyPrefix.      * @param files      *            A list of files to upload. The keys of the files are      *            calculated relative to the common parent directory and the      *            virtualDirectoryKeyPrefix.      */     public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files) {           return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, null);     }      /**      * Uploads all specified files to the bucket named, constructing      * relative keys depending on the commonParentDirectory given.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The common parent directory of files to upload. The keys      *            of the files in the list of files are constructed relative to      *            this directory and the virtualDirectoryKeyPrefix.      * @param files      *            A list of files to upload. The keys of the files are      *            calculated relative to the common parent directory and the      *            virtualDirectoryKeyPrefix.      * @param metadataProvider      *      A callback of type <code>ObjectMetadataProvider</code> which       *            is used to provide metadata for each file being uploaded.      */     public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files,ObjectMetadataProvider metadataProvider) {          if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a common base directory for uploaded files");         }          if (virtualDirectoryKeyPrefix == null || virtualDirectoryKeyPrefix.length() == 0) {             virtualDirectoryKeyPrefix = "";         } else if ( !virtualDirectoryKeyPrefix.endsWith("/") ) {             virtualDirectoryKeyPrefix = virtualDirectoryKeyPrefix + "/";         }          TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<UploadImpl> uploads = new LinkedList<UploadImpl>();         MultipleFileUploadImpl multipleFileUpload = new MultipleFileUploadImpl("Uploading etc", transferProgress, (ProgressListenerChain)null, virtualDirectoryKeyPrefix, bucketName, uploads);         multipleFileUpload.setMonitor(new MultipleFileTransferMonitor(multipleFileUpload, uploads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileUpload);          if ( files == null || files.isEmpty()) {             multipleFileUpload.setState(TransferState.Completed);         }          long totalSize = 0;         for (File f : files) {             //Check, if file, since only files can be uploaded.             if (f.isFile()) {                 totalSize += f.length();                 String key = f.getAbsolutePath().substring(directory.getAbsolutePath().length() + 1)                         .replaceAll("\\\\", "/");                                  ObjectMetadata metadata=new ObjectMetadata();                                  // Invoke the callback if it's present.                 // The callback allows the user to customize the metadata for each file being uploaded.                 if(metadataProvider!=null){                    metadataProvider.provideObjectMetadata(f,metadata);                 }                                  uploads.add((UploadImpl) upload(                         new PutObjectRequest(bucketName, virtualDirectoryKeyPrefix + key, f).withMetadata(metadata).withGeneralProgressListener(listener),                         stateChangeListener));             }         }          transferProgress.setTotalBytesToTransfer(totalSize);          // Notify all state changes waiting for the uploads to all be queued         // to wake up and continue         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileUpload;     }      /**      * Lists files in the directory given and adds them to the result list      * passed in, optionally adding subdirectories recursively.      */     private void listFiles(File dir, List<File> results, boolean includeSubDirectories) {         File[] found = dir.listFiles();         if ( found != null ) {             for ( File f : found ) {                 if (f.isDirectory()) {                     if (includeSubDirectories) {                         listFiles(f, results, includeSubDirectories);                     }                 } else {                     results.add(f);                 }             }         }     }      /**      * <p>      * Aborts any multipart uploads that were initiated before the specified date.      * </p>      * <p>      * This method is useful for cleaning up any interrupted multipart uploads.      * <code>TransferManager</code> attempts to abort any failed uploads,      * but in some cases this may not be possible, such as if network connectivity      * is completely lost.      * </p>      *      * @param bucketName      *            The name of the bucket containing the multipart uploads to      *            abort.      * @param date      *            The date indicating which multipart uploads should be aborted.      */     public void abortMultipartUploads(String bucketName, Date date)             throws AmazonServiceException, AmazonClientException {         MultipartUploadListing uploadListing = s3.listMultipartUploads(appendUserAgent(                 new ListMultipartUploadsRequest(bucketName), USER_AGENT));         do {             for (MultipartUpload upload : uploadListing.getMultipartUploads()) {                 if (upload.getInitiated().compareTo(date) < 0) {                     s3.abortMultipartUpload(appendUserAgent(new AbortMultipartUploadRequest(                             bucketName, upload.getKey(), upload.getUploadId()), USER_AGENT));                 }             }              ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName)                 .withUploadIdMarker(uploadListing.getNextUploadIdMarker())                 .withKeyMarker(uploadListing.getNextKeyMarker());             uploadListing = s3.listMultipartUploads(appendUserAgent(request, USER_AGENT));         } while (uploadListing.isTruncated());     }      /**      * Forcefully shuts down this TransferManager instance - currently executing      * transfers will not be allowed to finish. Callers should use this method      * when they either:      * <ul>      * <li>have already verified that their transfers have completed by checking      * each transfer's state      * <li>need to exit quickly and don't mind stopping transfers before they      * complete.      * </ul>      * <p>      * Callers should also remember that uploaded parts from an interrupted      * upload may not always be automatically cleaned up, but callers can use      * {@link #abortMultipartUploads(String, Date)} to clean up any upload      * parts.      */     public void shutdownNow() {         threadPool.shutdownNow();         timedThreadPool.shutdownNow();          if (s3 instanceof AmazonS3Client) {             ((AmazonS3Client)s3).shutdown();         }     }      public <X extends AmazonWebServiceRequest> X appendUserAgent(X request, String userAgent) {         request.getRequestClientOptions().addClientMarker(USER_AGENT);         return request;     }      private static final String USER_AGENT = TransferManager.class.getName() + "/" + VersionInfoUtils.getVersion();      private static final String DEFAULT_DELIMITER = "/"; } " compose:StringConcatenation merge: LineBased]
[NT -> base : Feature]
	[NT -> src : Folder]
		[NT -> main : Folder]
			[NT -> java : Folder]
				[NT -> com : Folder]
					[NT -> amazonaws : Folder]
						[NT -> services : Folder]
							[NT -> s3 : Folder]
								[NT -> transfer : Folder]
									[NT -> TransferManager.java.merge : .java.merge-File]
										[T -> TransferManager.java : .java-Content "/*  * Copyright 2010-2013 Amazon.com, Inc. or its affiliates. All Rights Reserved.  *  * Licensed under the Apache License, Version 2.0 (the "License").  * You may not use this file except in compliance with the License.  * A copy of the License is located at  *  *  http://aws.amazon.com/apache2.0  *  * or in the "license" file accompanying this file. This file is distributed  * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either  * express or implied. See the License for the specific language governing  * permissions and limitations under the License.  */ package com.amazonaws.services.s3.transfer;  import java.io.File; import java.io.InputStream; import java.util.ArrayList; import java.util.Date; import java.util.LinkedList; import java.util.List; import java.util.Stack; import java.util.concurrent.Callable; import java.util.concurrent.Future; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.ScheduledThreadPoolExecutor; import java.util.concurrent.ThreadPoolExecutor;  import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory;  import com.amazonaws.AmazonClientException; import com.amazonaws.AmazonServiceException; import com.amazonaws.AmazonWebServiceRequest; import com.amazonaws.auth.AWSCredentials; import com.amazonaws.services.s3.AmazonS3; import com.amazonaws.services.s3.AmazonS3Client; import com.amazonaws.services.s3.AmazonS3EncryptionClient; import com.amazonaws.services.s3.internal.Mimetypes; import com.amazonaws.services.s3.internal.ServiceUtils; import com.amazonaws.services.s3.model.AbortMultipartUploadRequest; import com.amazonaws.services.s3.model.GetObjectRequest; import com.amazonaws.services.s3.model.ListMultipartUploadsRequest; import com.amazonaws.services.s3.model.ListObjectsRequest; import com.amazonaws.services.s3.model.MultipartUpload; import com.amazonaws.services.s3.model.MultipartUploadListing; import com.amazonaws.services.s3.model.ObjectListing; import com.amazonaws.services.s3.model.ObjectMetadata; import com.amazonaws.services.s3.model.ProgressListener; import com.amazonaws.services.s3.model.PutObjectRequest; import com.amazonaws.services.s3.model.S3Object; import com.amazonaws.services.s3.model.S3ObjectSummary; import com.amazonaws.services.s3.transfer.Transfer.TransferState; import com.amazonaws.services.s3.transfer.internal.DownloadImpl; import com.amazonaws.services.s3.transfer.internal.DownloadMonitor; import com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl; import com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer; import com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor; import com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl; import com.amazonaws.services.s3.transfer.internal.ProgressListenerChain; import com.amazonaws.services.s3.transfer.internal.TransferManagerUtils; import com.amazonaws.services.s3.transfer.internal.TransferProgressImpl; import com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener; import com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener; import com.amazonaws.services.s3.transfer.internal.UploadCallable; import com.amazonaws.services.s3.transfer.internal.UploadImpl; import com.amazonaws.services.s3.transfer.internal.UploadMonitor; import com.amazonaws.util.VersionInfoUtils;  /**  * High level utility for managing transfers to Amazon S3.  * <p>  * <code>TransferManager</code> provides a simple API for uploading content to  * Amazon S3, and makes extensive use of Amazon S3 multipart uploads to achieve  * enhanced throughput, performance and reliability.  * <p>  * When possible, <code>TransferManager</code> attempts to use multiple threads  * to upload multiple parts of a single upload at once. When dealing with large  * content sizes and high bandwidth, this can have a significant increase on  * throughput.  * <p>  * <code>TransferManager</code> is responsible for managing resources such as  * connections and threads; share a single instance of  * <code>TransferManager</code> whenever possible. <code>TransferManager</code>,  * like all the client classes in the AWS SDK for Java, is thread safe.  * <p>  * Using <code>TransferManager</code> to upload options to Amazon S3 is easy:  *  * <pre>  * AWSCredentials myCredentials = new BasicAWSCredentials(...);  * TransferManager tx = new TransferManager(myCredentials);  * Upload myUpload = tx.upload(myBucket, myFile.getName(), myFile);  *  * // You can poll your transfer's status to check its progress  * if (myUpload.isDone() == false) {  *     System.out.println("Transfer: " + myUpload.getDescription());  *     System.out.println("  - State: " + myUpload.getState());  *     System.out.println("  - Progress: " + myUpload.getProgress().getBytesTransfered());  * }  *  * // Transfers also allow you to set a <code>ProgressListener</code> to receive  * // asynchronous notifications about your transfer's progress.  * myUpload.addProgressListener(myProgressListener);  *  * // Or you can block the current thread and wait for your transfer to  * // to complete.  If the transfer fails, this method will throw an  * // AmazonClientException or AmazonServiceException detailing the reason.  * myUpload.waitForCompletion();  * </pre>  * <p>  * Note: Transfers are stored in memory. If the JVM is restarted, previous  * transfers are no longer accessible. If needed, clean up any multipart uploads  * that are incomplete.  */ public class TransferManager {      /** The low level client we use to make the actual calls to Amazon S3. */     private AmazonS3 s3;      /** Configuration for how TransferManager processes requests. */     private TransferManagerConfiguration configuration;     /** The thread pool in which transfers are uploaded or downloaded. */     private ThreadPoolExecutor threadPool;      /** Thread used for periodicially checking transfers and updating thier state. */     private ScheduledExecutorService timedThreadPool = new ScheduledThreadPoolExecutor(1);      private static final Log log = LogFactory.getLog(TransferManager.class);       /**      * Constructs a new <code>TransferManager</code> and Amazon S3 client using      * the specified AWS security credentials.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      *      * @param credentials      *            The AWS security credentials to use when making authenticated      *            requests.      */     public TransferManager(AWSCredentials credentials) {         this(new AmazonS3Client(credentials));     }      /**      * Constructs a new <code>TransferManager</code>,      * specifying the client to use when making      * requests to Amazon S3.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      * </p>      *      * @param s3      *            The client to use when making requests to Amazon S3.      */     public TransferManager(AmazonS3 s3) {         this(s3, TransferManagerUtils.createDefaultExecutorService());     }      /**      * Constructs a new <code>TransferManager</code>      * specifying the client and thread pool to use when making      * requests to Amazon S3.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      *      * @param s3      *            The client to use when making requests to Amazon S3.      * @param threadPool      *            The thread pool in which to execute requests.      */     public TransferManager(AmazonS3 s3, ThreadPoolExecutor threadPool) {         this.s3 = s3;         this.threadPool = threadPool;         this.configuration = new TransferManagerConfiguration();     }       /**      * Sets the configuration which specifies how      * this <code>TransferManager</code> processes requests.      *      * @param configuration      *            The new configuration specifying how      *            this <code>TransferManager</code>      *            processes requests.      */     public void setConfiguration(TransferManagerConfiguration configuration) {         this.configuration = configuration;     }      /**      * Returns the configuration which specifies how      * this <code>TransferManager</code> processes requests.      *      * @return The configuration settings for this <code>TransferManager</code>.      */     public TransferManagerConfiguration getConfiguration() {         return configuration;     }      /**      * Returns the underlying Amazon S3 client used to make requests to      * Amazon S3.      *      * @return The underlying Amazon S3 client used to make requests to      *         Amazon S3.      */     public AmazonS3 getAmazonS3Client() {         return s3;     }      /**      * <p>      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * </p>      * <p>      * When uploading options from a stream, callers <b>must</b> supply the size of      * options in the stream through the content length field in the      * <code>ObjectMetadata</code> parameter.      * If no content length is specified for the input      * stream, then TransferManager will attempt to buffer all the stream      * contents in memory and upload the options as a traditional, single part      * upload. Because the entire stream contents must be buffered in memory,      * this can be very expensive, and should be avoided whenever possible.      * </p>      * <p>      * Use the returned <code>Upload<code> object to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * </p>      * <p>      * If resources are available, the upload will begin immediately.      * Otherwise, the upload is scheduled and started as soon as      * resources become available.      * </p>      *      * @param bucketName      *            The name of the bucket to upload the new object to.      * @param key      *            The key in the specified bucket by which to store the new      *            object.      * @param input      *            The input stream containing the options to upload to Amazon S3.      * @param objectMetadata      *            Additional information about the object being uploaded,      *            including the size of the options, content type, additional      *            custom user metadata, etc.      *      * @return A new <code>Upload<code> object to use to check      *      the state of the upload, listen for progress notifications,      *      and otherwise manage the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final String bucketName, final String key, final InputStream input, ObjectMetadata objectMetadata)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, input, objectMetadata));     }      /**      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * <p>      * The returned Upload object allows you to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * <p>      * If resources are available, the upload will begin immediately, otherwise      * it will be scheduled and started as soon as resources become available.      *      * @param bucketName      *            The name of the bucket to upload the new object to.      * @param key      *            The key in the specified bucket by which to store the new      *            object.      * @param file      *            The file to upload.      *      * @return A new Upload object which can be used to check state of the      *         upload, listen for progress notifications, and otherwise manage      *         the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final String bucketName, final String key, final File file)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, file));     }      /**      * <p>      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * </p>      * <p>      * Use the returned <code>Upload<code> object to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * </p>      * <p>      * If resources are available, the upload will begin immediately.      * Otherwise, the upload is scheduled and started as soon as      * resources become available.      * </p>      *      * @param putObjectRequest      *            The request containing all the parameters for the upload.      *      * @return A new <code>Upload<code> object to use to check      *      the state of the upload, listen for progress notifications,      *      and otherwise manage the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final PutObjectRequest putObjectRequest)         throws AmazonServiceException, AmazonClientException {         return upload(putObjectRequest, null);     }      /**      * Same as public version of upload, but attaches a      * {@link TransferStateChangeListener} to the upload object so that it can be      * monitored.      */     private Upload upload(final PutObjectRequest putObjectRequest, final TransferStateChangeListener stateListener)             throws AmazonServiceException, AmazonClientException {              appendUserAgent(putObjectRequest, USER_AGENT);              if (putObjectRequest.getMetadata() == null)                 putObjectRequest.setMetadata(new ObjectMetadata());             ObjectMetadata metadata = putObjectRequest.getMetadata();              if ( TransferManagerUtils.getRequestFile(putObjectRequest) != null ) {                 File file = TransferManagerUtils.getRequestFile(putObjectRequest);                  // Always set the content length, even if it's already set                 metadata.setContentLength(file.length());                  // Only set the content type if it hasn't already been set                 if ( metadata.getContentType() == null ) {                     metadata.setContentType(Mimetypes.getInstance().getMimetype(file));                 }             }              String description = "Uploading to " + putObjectRequest.getBucketName() + "/" + putObjectRequest.getKey();             TransferProgressImpl transferProgress = new TransferProgressImpl();             transferProgress.setTotalBytesToTransfer(TransferManagerUtils.getContentLength(putObjectRequest));              ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                     transferProgress), putObjectRequest.getProgressListener());             putObjectRequest.setProgressListener(listenerChain);              UploadImpl upload = new UploadImpl(description, transferProgress, listenerChain, stateListener);              UploadCallable uploadCallable = new UploadCallable(this, threadPool, upload, putObjectRequest, listenerChain);             UploadMonitor watcher = new UploadMonitor(this, upload, threadPool, uploadCallable, putObjectRequest, listenerChain);             watcher.setTimedThreadPool(timedThreadPool);             upload.setMonitor(watcher);              return upload;         }       /**      * Schedules a new transfer to download data from Amazon S3 and save it to      * the specified file. This method is non-blocking and returns immediately      * (i.e. before the data has been fully downloaded).      * <p>      * Use the returned Download object to query the progress of the transfer,      * add listeners for progress events, and wait for the download to complete.      *      * @param bucket      *            The name of the bucket containing the object to download.      * @param key      *            The key under which the object to download is stored.      * @param file      *            The file to download the object's data to.      *      * @return A new <code>Download</code> object to use to check the state of      *         the download, listen for progress notifications, and otherwise      *         manage the download.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Download download(String bucket, String key, File file) {         return download(new GetObjectRequest(bucket, key), file);     }      /**      * Schedules a new transfer to download data from Amazon S3 and save it to      * the specified file. This method is non-blocking and returns immediately      * (i.e. before the data has been fully downloaded).      * <p>      * Use the returned Download object to query the progress of the transfer,      * add listeners for progress events, and wait for the download to complete.      *      * @param getObjectRequest      *            The request containing all the parameters for the download.      * @param file      *            The file to download the object data to.      *      * @return A new <code>Download</code> object to use to check the state of      *         the download, listen for progress notifications, and otherwise      *         manage the download.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Download download(final GetObjectRequest getObjectRequest, final File file) {         return download(getObjectRequest, file, null);     }      /**      * Same as public interface, but adds a state listener so that callers can      * be notified of state changes to the download.      *      * @see TransferManager#download(GetObjectRequest, File)      */     private Download download(final GetObjectRequest getObjectRequest,                               final File file,                               final TransferStateChangeListener stateListener) {          appendUserAgent(getObjectRequest, USER_AGENT);          String description = "Downloading from " + getObjectRequest.getBucketName() + "/" + getObjectRequest.getKey();          // Add our own transfer progress listener         TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                 transferProgress), getObjectRequest.getProgressListener());         getObjectRequest.setProgressListener(listenerChain);         final ObjectMetadata objectMetadata = s3.getObjectMetadata(getObjectRequest.getBucketName(), getObjectRequest.getKey());          final StartDownloadLock startDownloadLock = new StartDownloadLock();         final DownloadImpl download = new DownloadImpl(description, transferProgress, listenerChain, null, stateListener);         long contentLength = objectMetadata.getContentLength();         if (getObjectRequest.getRange() != null && getObjectRequest.getRange().length == 2) {             long startingByte = getObjectRequest.getRange()[0];             long lastByte     = getObjectRequest.getRange()[1];             contentLength     = lastByte - startingByte;         }          transferProgress.setTotalBytesToTransfer(contentLength);          Future<?> future = threadPool.submit(new Callable<Object>() {             @Override             public Object call() throws Exception {                 try {                     synchronized (startDownloadLock) {                         if ( !startDownloadLock.downloadReady ) {                                 try {                                     startDownloadLock.wait();                                     } catch ( InterruptedException e ) {                                  throw new AmazonClientException("Couldn't wait for setting future into the monitor");                              }                          }                      }                     download.setState(TransferState.InProgress);                     S3Object s3Object = ServiceUtils.retryableDownloadS3ObjectToFile(file, new ServiceUtils.RetryableS3DownloadTask() {              @Override       public S3Object getS3ObjectStream() {        S3Object s3Object = s3.getObject(getObjectRequest);        download.setS3Object(s3Object);        return s3Object;       }              @Override       public boolean needIntegrityCheck() {                       // Don't perform the integrity check if the stream data is wrapped                       // in a decryption stream, or if we're only looking at a range of                       // the data, since otherwise the checksum won't match up.                       boolean performIntegrityCheck = true;                       if (getObjectRequest.getRange() != null) performIntegrityCheck = false;                       if (s3 instanceof AmazonS3EncryptionClient) performIntegrityCheck = false;                       return performIntegrityCheck;           }      });                                           if (s3Object == null) {                         download.setState(TransferState.Canceled);                         download.setMonitor(new DownloadMonitor(download, null));                         return download;                     }                       download.setState(TransferState.Completed);                     return true;                 } catch (Exception e) {                     // Downloads aren't allowed to move from canceled to failed                     if (download.getState() != TransferState.Canceled) {                         download.setState(TransferState.Failed);                     }                     throw e;                 }             }         });         download.setMonitor(new DownloadMonitor(download, future));         synchronized (startDownloadLock) {             startDownloadLock.downloadReady = true;             startDownloadLock.notify();         }         return download;     }      /**      * Downloads all objects in the virtual directory designated by the      * keyPrefix given to the destination directory given. All virtual      * subdirectories will be downloaded recursively.      *      * @param bucketName      *            The bucket containing the virtual directory      * @param keyPrefix      *            The key prefix for the virtual directory, or null for the      *            entire bucket. All subdirectories will be downloaded      *            recursively.      * @param destinationDirectory      *            The directory to place downloaded files. Subdirectories will      *            be created as necessary.      */     public MultipleFileDownload downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory) {          if ( keyPrefix == null )             keyPrefix = "";          List<S3ObjectSummary> objectSummaries = new LinkedList<S3ObjectSummary>();         Stack<String> commonPrefixes = new Stack<String>();         commonPrefixes.add(keyPrefix);         long totalSize = 0;          // Recurse all virtual subdirectories to get a list of object summaries.         // This is a depth-first search.         do {             String prefix = commonPrefixes.pop();             ObjectListing listObjectsResponse = null;              do {                 if ( listObjectsResponse == null ) {                     ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName)                             .withDelimiter(DEFAULT_DELIMITER).withPrefix(prefix);                     listObjectsResponse = s3.listObjects(listObjectsRequest);                 } else {                     listObjectsResponse = s3.listNextBatchOfObjects(listObjectsResponse);                 }                  for ( S3ObjectSummary s : listObjectsResponse.getObjectSummaries() ) {                     // Skip any files that are also virtual directories, since                     // we can't save both a directory and a file of the same                     // name.                     if ( !s.getKey().equals(prefix)                             && !listObjectsResponse.getCommonPrefixes().contains(s.getKey() + DEFAULT_DELIMITER) ) {                         objectSummaries.add(s);                         totalSize += s.getSize();                     } else {                         log.debug("Skipping download for object " + s.getKey()                                 + " since it is also a virtual directory");                     }                 }                  commonPrefixes.addAll(listObjectsResponse.getCommonPrefixes());             } while ( listObjectsResponse.isTruncated() );         } while ( !commonPrefixes.isEmpty() );          TransferProgressImpl transferProgress = new TransferProgressImpl();         transferProgress.setTotalBytesToTransfer(totalSize);         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<DownloadImpl> downloads = new ArrayList<DownloadImpl>();          String description = "Downloading from " + bucketName + "/" + keyPrefix;         final MultipleFileDownloadImpl multipleFileDownload = new MultipleFileDownloadImpl(description, transferProgress,                 new ProgressListenerChain(listener), keyPrefix, bucketName, downloads);         multipleFileDownload.setMonitor(new MultipleFileTransferMonitor(multipleFileDownload, downloads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileDownload);          for ( S3ObjectSummary summary : objectSummaries ) {             // TODO: non-standard delimiters             File f = new File(destinationDirectory, summary.getKey());             File parentFile = f.getParentFile();             if ( !parentFile.exists() && !parentFile.mkdirs() ) {                 throw new RuntimeException("Couldn't create parent directories for " + f.getAbsolutePath());             }              downloads.add((DownloadImpl) download(                     new GetObjectRequest(summary.getBucketName(), summary.getKey()).withProgressListener(listener), f,                     stateChangeListener));         }          if ( downloads.isEmpty() ) {             multipleFileDownload.setState(TransferState.Completed);             return multipleFileDownload;         }          // Notify all state changes waiting for the downloads to all be queued         // to wake up and continue.         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileDownload;     }      private static final class AllDownloadsQueuedLock {         private volatile boolean allQueued = false;     }      private  static final class StartDownloadLock {         private volatile boolean downloadReady = false;     }      private static final class MultipleFileTransferStateChangeListener implements TransferStateChangeListener {          private final AllDownloadsQueuedLock allTransfersQueuedLock;         private final MultipleFileTransfer multipleFileTransfer;          public MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock allTransfersQueuedLock,                 MultipleFileTransfer multipleFileDownload) {             this.allTransfersQueuedLock = allTransfersQueuedLock;             this.multipleFileTransfer = multipleFileDownload;         }          @Override         public void transferStateChanged(Transfer upload, TransferState state) {              // There's a race here: we can't start monitoring the state of             // individual transfers until we have added all the transfers to the             // list, or we may incorrectly report completion.             synchronized (allTransfersQueuedLock) {                 if ( !allTransfersQueuedLock.allQueued ) {                     try {                         allTransfersQueuedLock.wait();                     } catch ( InterruptedException e ) {                         throw new AmazonClientException("Couldn't wait for all downloads to be queued");                     }                 }             }              synchronized (multipleFileTransfer) {                 if ( multipleFileTransfer.getState() == state || multipleFileTransfer.isDone() )                     return;                  /*                  * If we're not already in a terminal state, allow a transition                  * to a non-waiting state. Mark completed if this download is                  * completed and the monitor says all of the rest are as well.                  */                 if ( state == TransferState.InProgress ) {                     multipleFileTransfer.setState(state);                 } else if ( multipleFileTransfer.getMonitor().isDone() ) {                     multipleFileTransfer.collateFinalState();                 } else {                     multipleFileTransfer.setState(TransferState.InProgress);                 }             }         }     };      /**      * Uploads all files in the directory given to the bucket named, optionally      * recursing for all subdirectories.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The directory to upload.      * @param includeSubdirectories      *            Whether to include subdirectories in the upload. If true,      *            files found in subdirectories will be included with an      *            appropriate concatenation to the key prefix.      */     public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories) {      return uploadDirectory(bucketName, virtualDirectoryKeyPrefix, directory, includeSubdirectories, null);     }          /**      * Uploads all files in the directory given to the bucket named, optionally      * recursing for all subdirectories.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The directory to upload.                        * @param includeSubdirectories      *            Whether to include subdirectories in the upload. If true,      *            files found in subdirectories will be included with an      *            appropriate concatenation to the key prefix.      * @param metadataProvider      *      A callback of type <code>ObjectMetadataProvider</code> which       *            is used to provide metadata for each file being uploaded.      */     public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories, ObjectMetadataProvider metadataProvider) {      if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a directory to upload");         }          List<File> files = new LinkedList<File>();         listFiles(directory, files, includeSubdirectories);                  return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, metadataProvider);     }          /**      * Uploads all specified files to the bucket named, constructing      * relative keys depending on the commonParentDirectory given.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The common parent directory of files to upload. The keys      *            of the files in the list of files are constructed relative to      *            this directory and the virtualDirectoryKeyPrefix.      * @param files      *            A list of files to upload. The keys of the files are      *            calculated relative to the common parent directory and the      *            virtualDirectoryKeyPrefix.      */     public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files) {           return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, null);     }      /**      * Uploads all specified files to the bucket named, constructing      * relative keys depending on the commonParentDirectory given.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The common parent directory of files to upload. The keys      *            of the files in the list of files are constructed relative to      *            this directory and the virtualDirectoryKeyPrefix.      * @param files      *            A list of files to upload. The keys of the files are      *            calculated relative to the common parent directory and the      *            virtualDirectoryKeyPrefix.      * @param metadataProvider      *      A callback of type <code>ObjectMetadataProvider</code> which       *            is used to provide metadata for each file being uploaded.      */     public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files,ObjectMetadataProvider metadataProvider) {          if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a common base directory for uploaded files");         }          if (virtualDirectoryKeyPrefix == null || virtualDirectoryKeyPrefix.length() == 0) {             virtualDirectoryKeyPrefix = "";         } else if ( !virtualDirectoryKeyPrefix.endsWith("/") ) {             virtualDirectoryKeyPrefix = virtualDirectoryKeyPrefix + "/";         }          TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<UploadImpl> uploads = new LinkedList<UploadImpl>();         MultipleFileUploadImpl multipleFileUpload = new MultipleFileUploadImpl("Uploading etc", transferProgress, null, virtualDirectoryKeyPrefix, bucketName, uploads);         multipleFileUpload.setMonitor(new MultipleFileTransferMonitor(multipleFileUpload, uploads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileUpload);          if ( files == null || files.isEmpty()) {             multipleFileUpload.setState(TransferState.Completed);         }          long totalSize = 0;         for (File f : files) {             //Check, if file, since only files can be uploaded.             if (f.isFile()) {                 totalSize += f.length();                 String key = f.getAbsolutePath().substring(directory.getAbsolutePath().length() + 1)                         .replaceAll("\\\\", "/");                                  ObjectMetadata metadata=new ObjectMetadata();                                  // Invoke the callback if it's present.                 // The callback allows the user to customize the metadata for each file being uploaded.                 if(metadataProvider!=null){                    metadataProvider.provideObjectMetadata(f,metadata);                 }                                  uploads.add((UploadImpl) upload(                         new PutObjectRequest(bucketName, virtualDirectoryKeyPrefix + key, f).withMetadata(metadata).withProgressListener(listener),                         stateChangeListener));             }         }          transferProgress.setTotalBytesToTransfer(totalSize);          // Notify all state changes waiting for the uploads to all be queued         // to wake up and continue         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileUpload;     }      /**      * Lists files in the directory given and adds them to the result list      * passed in, optionally adding subdirectories recursively.      */     private void listFiles(File dir, List<File> results, boolean includeSubDirectories) {         File[] found = dir.listFiles();         if ( found != null ) {             for ( File f : found ) {                 if (f.isDirectory()) {                     if (includeSubDirectories) {                         listFiles(f, results, includeSubDirectories);                     }                 } else {                     results.add(f);                 }             }         }     }      /**      * <p>      * Aborts any multipart uploads that were initiated before the specified date.      * </p>      * <p>      * This method is useful for cleaning up any interrupted multipart uploads.      * <code>TransferManager</code> attempts to abort any failed uploads,      * but in some cases this may not be possible, such as if network connectivity      * is completely lost.      * </p>      *      * @param bucketName      *            The name of the bucket containing the multipart uploads to      *            abort.      * @param date      *            The date indicating which multipart uploads should be aborted.      */     public void abortMultipartUploads(String bucketName, Date date)             throws AmazonServiceException, AmazonClientException {         MultipartUploadListing uploadListing = s3.listMultipartUploads(appendUserAgent(                 new ListMultipartUploadsRequest(bucketName), USER_AGENT));         do {             for (MultipartUpload upload : uploadListing.getMultipartUploads()) {                 if (upload.getInitiated().compareTo(date) < 0) {                     s3.abortMultipartUpload(appendUserAgent(new AbortMultipartUploadRequest(                             bucketName, upload.getKey(), upload.getUploadId()), USER_AGENT));                 }             }              ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName)                 .withUploadIdMarker(uploadListing.getNextUploadIdMarker())                 .withKeyMarker(uploadListing.getNextKeyMarker());             uploadListing = s3.listMultipartUploads(appendUserAgent(request, USER_AGENT));         } while (uploadListing.isTruncated());     }      /**      * Forcefully shuts down this TransferManager instance - currently executing      * transfers will not be allowed to finish. Callers should use this method      * when they either:      * <ul>      * <li>have already verified that their transfers have completed by checking      * each transfer's state      * <li>need to exit quickly and don't mind stopping transfers before they      * complete.      * </ul>      * <p>      * Callers should also remember that uploaded parts from an interrupted      * upload may not always be automatically cleaned up, but callers can use      * {@link #abortMultipartUploads(String, Date)} to clean up any upload      * parts.      */     public void shutdownNow() {         threadPool.shutdownNow();         timedThreadPool.shutdownNow();          if (s3 instanceof AmazonS3Client) {             ((AmazonS3Client)s3).shutdown();         }     }      public <X extends AmazonWebServiceRequest> X appendUserAgent(X request, String userAgent) {         request.getRequestClientOptions().addClientMarker(USER_AGENT);         return request;     }      private static final String USER_AGENT = TransferManager.class.getName() + "/" + VersionInfoUtils.getVersion();      private static final String DEFAULT_DELIMITER = "/"; } " compose:StringConcatenation merge: LineBased]
[NT -> right : Feature]
	[NT -> src : Folder]
		[NT -> main : Folder]
			[NT -> java : Folder]
				[NT -> com : Folder]
					[NT -> amazonaws : Folder]
						[NT -> services : Folder]
							[NT -> s3 : Folder]
								[NT -> transfer : Folder]
									[NT -> TransferManager.java.merge : .java.merge-File]
										[T -> TransferManager.java : .java-Content "/*  * Copyright 2010-2013 Amazon.com, Inc. or its affiliates. All Rights Reserved.  *  * Licensed under the Apache License, Version 2.0 (the "License").  * You may not use this file except in compliance with the License.  * A copy of the License is located at  *  *  http://aws.amazon.com/apache2.0  *  * or in the "license" file accompanying this file. This file is distributed  * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either  * express or implied. See the License for the specific language governing  * permissions and limitations under the License.  */ package com.amazonaws.services.s3.transfer;  import java.io.File; import java.io.InputStream; import java.util.ArrayList; import java.util.Date; import java.util.LinkedList; import java.util.List; import java.util.Stack; import java.util.concurrent.Callable; import java.util.concurrent.Future; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.ScheduledThreadPoolExecutor; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.ThreadFactory; import java.util.concurrent.atomic.AtomicInteger;  import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory;  import com.amazonaws.AmazonClientException; import com.amazonaws.AmazonServiceException; import com.amazonaws.AmazonWebServiceRequest; import com.amazonaws.auth.AWSCredentials; import com.amazonaws.services.s3.AmazonS3; import com.amazonaws.services.s3.AmazonS3Client; import com.amazonaws.services.s3.AmazonS3EncryptionClient; import com.amazonaws.services.s3.internal.Mimetypes; import com.amazonaws.services.s3.internal.ServiceUtils; import com.amazonaws.services.s3.model.AbortMultipartUploadRequest; import com.amazonaws.services.s3.model.GetObjectRequest; import com.amazonaws.services.s3.model.ListMultipartUploadsRequest; import com.amazonaws.services.s3.model.ListObjectsRequest; import com.amazonaws.services.s3.model.MultipartUpload; import com.amazonaws.services.s3.model.MultipartUploadListing; import com.amazonaws.services.s3.model.ObjectListing; import com.amazonaws.services.s3.model.ObjectMetadata; import com.amazonaws.services.s3.model.ProgressListener; import com.amazonaws.services.s3.model.PutObjectRequest; import com.amazonaws.services.s3.model.S3Object; import com.amazonaws.services.s3.model.S3ObjectSummary; import com.amazonaws.services.s3.transfer.Transfer.TransferState; import com.amazonaws.services.s3.transfer.internal.DownloadImpl; import com.amazonaws.services.s3.transfer.internal.DownloadMonitor; import com.amazonaws.services.s3.transfer.internal.MultipleFileDownloadImpl; import com.amazonaws.services.s3.transfer.internal.MultipleFileTransfer; import com.amazonaws.services.s3.transfer.internal.MultipleFileTransferMonitor; import com.amazonaws.services.s3.transfer.internal.MultipleFileUploadImpl; import com.amazonaws.services.s3.transfer.internal.ProgressListenerChain; import com.amazonaws.services.s3.transfer.internal.TransferManagerUtils; import com.amazonaws.services.s3.transfer.internal.TransferProgressImpl; import com.amazonaws.services.s3.transfer.internal.TransferProgressUpdatingListener; import com.amazonaws.services.s3.transfer.internal.TransferStateChangeListener; import com.amazonaws.services.s3.transfer.internal.UploadCallable; import com.amazonaws.services.s3.transfer.internal.UploadImpl; import com.amazonaws.services.s3.transfer.internal.UploadMonitor; import com.amazonaws.util.VersionInfoUtils;  /**  * High level utility for managing transfers to Amazon S3.  * <p>  * <code>TransferManager</code> provides a simple API for uploading content to  * Amazon S3, and makes extensive use of Amazon S3 multipart uploads to achieve  * enhanced throughput, performance and reliability.  * <p>  * When possible, <code>TransferManager</code> attempts to use multiple threads  * to upload multiple parts of a single upload at once. When dealing with large  * content sizes and high bandwidth, this can have a significant increase on  * throughput.  * <p>  * <code>TransferManager</code> is responsible for managing resources such as  * connections and threads; share a single instance of  * <code>TransferManager</code> whenever possible. <code>TransferManager</code>,  * like all the client classes in the AWS SDK for Java, is thread safe.  * <p>  * Using <code>TransferManager</code> to upload options to Amazon S3 is easy:  *  * <pre>  * AWSCredentials myCredentials = new BasicAWSCredentials(...);  * TransferManager tx = new TransferManager(myCredentials);  * Upload myUpload = tx.upload(myBucket, myFile.getName(), myFile);  *  * // You can poll your transfer's status to check its progress  * if (myUpload.isDone() == false) {  *     System.out.println("Transfer: " + myUpload.getDescription());  *     System.out.println("  - State: " + myUpload.getState());  *     System.out.println("  - Progress: " + myUpload.getProgress().getBytesTransfered());  * }  *  * // Transfers also allow you to set a <code>ProgressListener</code> to receive  * // asynchronous notifications about your transfer's progress.  * myUpload.addProgressListener(myProgressListener);  *  * // Or you can block the current thread and wait for your transfer to  * // to complete.  If the transfer fails, this method will throw an  * // AmazonClientException or AmazonServiceException detailing the reason.  * myUpload.waitForCompletion();  * </pre>  * <p>  * Note: Transfers are stored in memory. If the JVM is restarted, previous  * transfers are no longer accessible. If needed, clean up any multipart uploads  * that are incomplete.  */ public class TransferManager {      /** The low level client we use to make the actual calls to Amazon S3. */     private AmazonS3 s3;      /** Configuration for how TransferManager processes requests. */     private TransferManagerConfiguration configuration;     /** The thread pool in which transfers are uploaded or downloaded. */     private ThreadPoolExecutor threadPool;      /** Thread used for periodicially checking transfers and updating thier state. */     private ScheduledExecutorService timedThreadPool = new ScheduledThreadPoolExecutor(1, daemonThreadFactory);      private static final Log log = LogFactory.getLog(TransferManager.class);       /**      * Constructs a new <code>TransferManager</code> and Amazon S3 client using      * the specified AWS security credentials.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      *      * @param credentials      *            The AWS security credentials to use when making authenticated      *            requests.      */     public TransferManager(AWSCredentials credentials) {         this(new AmazonS3Client(credentials));     }      /**      * Constructs a new <code>TransferManager</code>,      * specifying the client to use when making      * requests to Amazon S3.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      * </p>      *      * @param s3      *            The client to use when making requests to Amazon S3.      */     public TransferManager(AmazonS3 s3) {         this(s3, TransferManagerUtils.createDefaultExecutorService());     }      /**      * Constructs a new <code>TransferManager</code>      * specifying the client and thread pool to use when making      * requests to Amazon S3.      * <p>      * <code>TransferManager</code> and client objects      * may pool connections and threads.      * Reuse <code>TransferManager</code> and client objects      * and share them throughout applications.      * <p>      * TransferManager and all AWS client objects are thread safe.      *      * @param s3      *            The client to use when making requests to Amazon S3.      * @param threadPool      *            The thread pool in which to execute requests.      */     public TransferManager(AmazonS3 s3, ThreadPoolExecutor threadPool) {         this.s3 = s3;         this.threadPool = threadPool;         this.configuration = new TransferManagerConfiguration();     }       /**      * Sets the configuration which specifies how      * this <code>TransferManager</code> processes requests.      *      * @param configuration      *            The new configuration specifying how      *            this <code>TransferManager</code>      *            processes requests.      */     public void setConfiguration(TransferManagerConfiguration configuration) {         this.configuration = configuration;     }      /**      * Returns the configuration which specifies how      * this <code>TransferManager</code> processes requests.      *      * @return The configuration settings for this <code>TransferManager</code>.      */     public TransferManagerConfiguration getConfiguration() {         return configuration;     }      /**      * Returns the underlying Amazon S3 client used to make requests to      * Amazon S3.      *      * @return The underlying Amazon S3 client used to make requests to      *         Amazon S3.      */     public AmazonS3 getAmazonS3Client() {         return s3;     }      /**      * <p>      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * </p>      * <p>      * When uploading options from a stream, callers <b>must</b> supply the size of      * options in the stream through the content length field in the      * <code>ObjectMetadata</code> parameter.      * If no content length is specified for the input      * stream, then TransferManager will attempt to buffer all the stream      * contents in memory and upload the options as a traditional, single part      * upload. Because the entire stream contents must be buffered in memory,      * this can be very expensive, and should be avoided whenever possible.      * </p>      * <p>      * Use the returned <code>Upload<code> object to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * </p>      * <p>      * If resources are available, the upload will begin immediately.      * Otherwise, the upload is scheduled and started as soon as      * resources become available.      * </p>      *      * @param bucketName      *            The name of the bucket to upload the new object to.      * @param key      *            The key in the specified bucket by which to store the new      *            object.      * @param input      *            The input stream containing the options to upload to Amazon S3.      * @param objectMetadata      *            Additional information about the object being uploaded,      *            including the size of the options, content type, additional      *            custom user metadata, etc.      *      * @return A new <code>Upload<code> object to use to check      *      the state of the upload, listen for progress notifications,      *      and otherwise manage the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final String bucketName, final String key, final InputStream input, ObjectMetadata objectMetadata)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, input, objectMetadata));     }      /**      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * <p>      * The returned Upload object allows you to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * <p>      * If resources are available, the upload will begin immediately, otherwise      * it will be scheduled and started as soon as resources become available.      *      * @param bucketName      *            The name of the bucket to upload the new object to.      * @param key      *            The key in the specified bucket by which to store the new      *            object.      * @param file      *            The file to upload.      *      * @return A new Upload object which can be used to check state of the      *         upload, listen for progress notifications, and otherwise manage      *         the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final String bucketName, final String key, final File file)         throws AmazonServiceException, AmazonClientException {         return upload(new PutObjectRequest(bucketName, key, file));     }      /**      * <p>      * Schedules a new transfer to upload data to Amazon S3. This method is      * non-blocking and returns immediately (i.e. before the upload has      * finished).      * </p>      * <p>      * Use the returned <code>Upload<code> object to query the progress of the      * transfer, add listeners for progress events, and wait for the upload to      * complete.      * </p>      * <p>      * If resources are available, the upload will begin immediately.      * Otherwise, the upload is scheduled and started as soon as      * resources become available.      * </p>      *      * @param putObjectRequest      *            The request containing all the parameters for the upload.      *      * @return A new <code>Upload<code> object to use to check      *      the state of the upload, listen for progress notifications,      *      and otherwise manage the upload.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Upload upload(final PutObjectRequest putObjectRequest)         throws AmazonServiceException, AmazonClientException {         return upload(putObjectRequest, null);     }      /**      * Same as public version of upload, but attaches a      * {@link TransferStateChangeListener} to the upload object so that it can be      * monitored.      */     private Upload upload(final PutObjectRequest putObjectRequest, final TransferStateChangeListener stateListener)             throws AmazonServiceException, AmazonClientException {              appendUserAgent(putObjectRequest, USER_AGENT);              if (putObjectRequest.getMetadata() == null)                 putObjectRequest.setMetadata(new ObjectMetadata());             ObjectMetadata metadata = putObjectRequest.getMetadata();              if ( TransferManagerUtils.getRequestFile(putObjectRequest) != null ) {                 File file = TransferManagerUtils.getRequestFile(putObjectRequest);                  // Always set the content length, even if it's already set                 metadata.setContentLength(file.length());                  // Only set the content type if it hasn't already been set                 if ( metadata.getContentType() == null ) {                     metadata.setContentType(Mimetypes.getInstance().getMimetype(file));                 }             }              String description = "Uploading to " + putObjectRequest.getBucketName() + "/" + putObjectRequest.getKey();             TransferProgressImpl transferProgress = new TransferProgressImpl();             transferProgress.setTotalBytesToTransfer(TransferManagerUtils.getContentLength(putObjectRequest));              ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                     transferProgress), putObjectRequest.getProgressListener());             putObjectRequest.setProgressListener(listenerChain);              UploadImpl upload = new UploadImpl(description, transferProgress, listenerChain, stateListener);              UploadCallable uploadCallable = new UploadCallable(this, threadPool, upload, putObjectRequest, listenerChain);             UploadMonitor watcher = new UploadMonitor(this, upload, threadPool, uploadCallable, putObjectRequest, listenerChain);             watcher.setTimedThreadPool(timedThreadPool);             upload.setMonitor(watcher);              return upload;         }       /**      * Schedules a new transfer to download data from Amazon S3 and save it to      * the specified file. This method is non-blocking and returns immediately      * (i.e. before the data has been fully downloaded).      * <p>      * Use the returned Download object to query the progress of the transfer,      * add listeners for progress events, and wait for the download to complete.      *      * @param bucket      *            The name of the bucket containing the object to download.      * @param key      *            The key under which the object to download is stored.      * @param file      *            The file to download the object's data to.      *      * @return A new <code>Download</code> object to use to check the state of      *         the download, listen for progress notifications, and otherwise      *         manage the download.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Download download(String bucket, String key, File file) {         return download(new GetObjectRequest(bucket, key), file);     }      /**      * Schedules a new transfer to download data from Amazon S3 and save it to      * the specified file. This method is non-blocking and returns immediately      * (i.e. before the data has been fully downloaded).      * <p>      * Use the returned Download object to query the progress of the transfer,      * add listeners for progress events, and wait for the download to complete.      *      * @param getObjectRequest      *            The request containing all the parameters for the download.      * @param file      *            The file to download the object data to.      *      * @return A new <code>Download</code> object to use to check the state of      *         the download, listen for progress notifications, and otherwise      *         manage the download.      *      * @throws AmazonClientException      *             If any errors are encountered in the client while making the      *             request or handling the response.      * @throws AmazonServiceException      *             If any errors occurred in Amazon S3 while processing the      *             request.      */     public Download download(final GetObjectRequest getObjectRequest, final File file) {         return download(getObjectRequest, file, null);     }      /**      * Same as public interface, but adds a state listener so that callers can      * be notified of state changes to the download.      *      * @see TransferManager#download(GetObjectRequest, File)      */     private Download download(final GetObjectRequest getObjectRequest,                               final File file,                               final TransferStateChangeListener stateListener) {          appendUserAgent(getObjectRequest, USER_AGENT);          String description = "Downloading from " + getObjectRequest.getBucketName() + "/" + getObjectRequest.getKey();          // Add our own transfer progress listener         TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListenerChain listenerChain = new ProgressListenerChain(new TransferProgressUpdatingListener(                 transferProgress), getObjectRequest.getProgressListener());         getObjectRequest.setProgressListener(listenerChain);         final ObjectMetadata objectMetadata = s3.getObjectMetadata(getObjectRequest.getBucketName(), getObjectRequest.getKey());          final StartDownloadLock startDownloadLock = new StartDownloadLock();         final DownloadImpl download = new DownloadImpl(description, transferProgress, listenerChain, null, stateListener);         long contentLength = objectMetadata.getContentLength();         if (getObjectRequest.getRange() != null && getObjectRequest.getRange().length == 2) {             long startingByte = getObjectRequest.getRange()[0];             long lastByte     = getObjectRequest.getRange()[1];             contentLength     = lastByte - startingByte;         }          transferProgress.setTotalBytesToTransfer(contentLength);          Future<?> future = threadPool.submit(new Callable<Object>() {             @Override             public Object call() throws Exception {                 try {                     synchronized (startDownloadLock) {                         if ( !startDownloadLock.downloadReady ) {                                 try {                                     startDownloadLock.wait();                                     } catch ( InterruptedException e ) {                                  throw new AmazonClientException("Couldn't wait for setting future into the monitor");                              }                          }                      }                     download.setState(TransferState.InProgress);                     S3Object s3Object = ServiceUtils.retryableDownloadS3ObjectToFile(file, new ServiceUtils.RetryableS3DownloadTask() {              @Override       public S3Object getS3ObjectStream() {        S3Object s3Object = s3.getObject(getObjectRequest);        download.setS3Object(s3Object);        return s3Object;       }              @Override       public boolean needIntegrityCheck() {                       // Don't perform the integrity check if the stream data is wrapped                       // in a decryption stream, or if we're only looking at a range of                       // the data, since otherwise the checksum won't match up.                       boolean performIntegrityCheck = true;                       if (getObjectRequest.getRange() != null) performIntegrityCheck = false;                       if (s3 instanceof AmazonS3EncryptionClient) performIntegrityCheck = false;                       return performIntegrityCheck;           }      });                                           if (s3Object == null) {                         download.setState(TransferState.Canceled);                         download.setMonitor(new DownloadMonitor(download, null));                         return download;                     }                       download.setState(TransferState.Completed);                     return true;                 } catch (Exception e) {                     // Downloads aren't allowed to move from canceled to failed                     if (download.getState() != TransferState.Canceled) {                         download.setState(TransferState.Failed);                     }                     throw e;                 }             }         });         download.setMonitor(new DownloadMonitor(download, future));         synchronized (startDownloadLock) {             startDownloadLock.downloadReady = true;             startDownloadLock.notify();         }         return download;     }      /**      * Downloads all objects in the virtual directory designated by the      * keyPrefix given to the destination directory given. All virtual      * subdirectories will be downloaded recursively.      *      * @param bucketName      *            The bucket containing the virtual directory      * @param keyPrefix      *            The key prefix for the virtual directory, or null for the      *            entire bucket. All subdirectories will be downloaded      *            recursively.      * @param destinationDirectory      *            The directory to place downloaded files. Subdirectories will      *            be created as necessary.      */     public MultipleFileDownload downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory) {          if ( keyPrefix == null )             keyPrefix = "";          List<S3ObjectSummary> objectSummaries = new LinkedList<S3ObjectSummary>();         Stack<String> commonPrefixes = new Stack<String>();         commonPrefixes.add(keyPrefix);         long totalSize = 0;          // Recurse all virtual subdirectories to get a list of object summaries.         // This is a depth-first search.         do {             String prefix = commonPrefixes.pop();             ObjectListing listObjectsResponse = null;              do {                 if ( listObjectsResponse == null ) {                     ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucketName)                             .withDelimiter(DEFAULT_DELIMITER).withPrefix(prefix);                     listObjectsResponse = s3.listObjects(listObjectsRequest);                 } else {                     listObjectsResponse = s3.listNextBatchOfObjects(listObjectsResponse);                 }                  for ( S3ObjectSummary s : listObjectsResponse.getObjectSummaries() ) {                     // Skip any files that are also virtual directories, since                     // we can't save both a directory and a file of the same                     // name.                     if ( !s.getKey().equals(prefix)                             && !listObjectsResponse.getCommonPrefixes().contains(s.getKey() + DEFAULT_DELIMITER) ) {                         objectSummaries.add(s);                         totalSize += s.getSize();                     } else {                         log.debug("Skipping download for object " + s.getKey()                                 + " since it is also a virtual directory");                     }                 }                  commonPrefixes.addAll(listObjectsResponse.getCommonPrefixes());             } while ( listObjectsResponse.isTruncated() );         } while ( !commonPrefixes.isEmpty() );          TransferProgressImpl transferProgress = new TransferProgressImpl();         transferProgress.setTotalBytesToTransfer(totalSize);         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<DownloadImpl> downloads = new ArrayList<DownloadImpl>();          String description = "Downloading from " + bucketName + "/" + keyPrefix;         final MultipleFileDownloadImpl multipleFileDownload = new MultipleFileDownloadImpl(description, transferProgress,                 new ProgressListenerChain(listener), keyPrefix, bucketName, downloads);         multipleFileDownload.setMonitor(new MultipleFileTransferMonitor(multipleFileDownload, downloads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileDownload);          for ( S3ObjectSummary summary : objectSummaries ) {             // TODO: non-standard delimiters             File f = new File(destinationDirectory, summary.getKey());             File parentFile = f.getParentFile();             if ( !parentFile.exists() && !parentFile.mkdirs() ) {                 throw new RuntimeException("Couldn't create parent directories for " + f.getAbsolutePath());             }              downloads.add((DownloadImpl) download(                     new GetObjectRequest(summary.getBucketName(), summary.getKey()).withProgressListener(listener), f,                     stateChangeListener));         }          if ( downloads.isEmpty() ) {             multipleFileDownload.setState(TransferState.Completed);             return multipleFileDownload;         }          // Notify all state changes waiting for the downloads to all be queued         // to wake up and continue.         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileDownload;     }      private static final class AllDownloadsQueuedLock {         private volatile boolean allQueued = false;     }      private  static final class StartDownloadLock {         private volatile boolean downloadReady = false;     }      private static final class MultipleFileTransferStateChangeListener implements TransferStateChangeListener {          private final AllDownloadsQueuedLock allTransfersQueuedLock;         private final MultipleFileTransfer multipleFileTransfer;          public MultipleFileTransferStateChangeListener(AllDownloadsQueuedLock allTransfersQueuedLock,                 MultipleFileTransfer multipleFileDownload) {             this.allTransfersQueuedLock = allTransfersQueuedLock;             this.multipleFileTransfer = multipleFileDownload;         }          @Override         public void transferStateChanged(Transfer upload, TransferState state) {              // There's a race here: we can't start monitoring the state of             // individual transfers until we have added all the transfers to the             // list, or we may incorrectly report completion.             synchronized (allTransfersQueuedLock) {                 if ( !allTransfersQueuedLock.allQueued ) {                     try {                         allTransfersQueuedLock.wait();                     } catch ( InterruptedException e ) {                         throw new AmazonClientException("Couldn't wait for all downloads to be queued");                     }                 }             }              synchronized (multipleFileTransfer) {                 if ( multipleFileTransfer.getState() == state || multipleFileTransfer.isDone() )                     return;                  /*                  * If we're not already in a terminal state, allow a transition                  * to a non-waiting state. Mark completed if this download is                  * completed and the monitor says all of the rest are as well.                  */                 if ( state == TransferState.InProgress ) {                     multipleFileTransfer.setState(state);                 } else if ( multipleFileTransfer.getMonitor().isDone() ) {                     multipleFileTransfer.collateFinalState();                 } else {                     multipleFileTransfer.setState(TransferState.InProgress);                 }             }         }     };      /**      * Uploads all files in the directory given to the bucket named, optionally      * recursing for all subdirectories.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The directory to upload.      * @param includeSubdirectories      *            Whether to include subdirectories in the upload. If true,      *            files found in subdirectories will be included with an      *            appropriate concatenation to the key prefix.      */     public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories) {      return uploadDirectory(bucketName, virtualDirectoryKeyPrefix, directory, includeSubdirectories, null);     }          /**      * Uploads all files in the directory given to the bucket named, optionally      * recursing for all subdirectories.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The directory to upload.                        * @param includeSubdirectories      *            Whether to include subdirectories in the upload. If true,      *            files found in subdirectories will be included with an      *            appropriate concatenation to the key prefix.      * @param metadataProvider      *      A callback of type <code>ObjectMetadataProvider</code> which       *            is used to provide metadata for each file being uploaded.      */     public MultipleFileUpload uploadDirectory(String bucketName, String virtualDirectoryKeyPrefix, File directory, boolean includeSubdirectories, ObjectMetadataProvider metadataProvider) {      if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a directory to upload");         }          List<File> files = new LinkedList<File>();         listFiles(directory, files, includeSubdirectories);                  return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, metadataProvider);     }          /**      * Uploads all specified files to the bucket named, constructing      * relative keys depending on the commonParentDirectory given.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The common parent directory of files to upload. The keys      *            of the files in the list of files are constructed relative to      *            this directory and the virtualDirectoryKeyPrefix.      * @param files      *            A list of files to upload. The keys of the files are      *            calculated relative to the common parent directory and the      *            virtualDirectoryKeyPrefix.      */     public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files) {           return uploadFileList(bucketName, virtualDirectoryKeyPrefix, directory, files, null);     }      /**      * Uploads all specified files to the bucket named, constructing      * relative keys depending on the commonParentDirectory given.      * <p>      * S3 will overwrite any existing objects that happen to have the same key,      * just as when uploading individual files, so use with caution.      *      * @param bucketName      *            The name of the bucket to upload objects to.      * @param virtualDirectoryKeyPrefix      *            The key prefix of the virtual directory to upload to. Use the      *            null or empty string to upload files to the root of the      *            bucket.      * @param directory      *            The common parent directory of files to upload. The keys      *            of the files in the list of files are constructed relative to      *            this directory and the virtualDirectoryKeyPrefix.      * @param files      *            A list of files to upload. The keys of the files are      *            calculated relative to the common parent directory and the      *            virtualDirectoryKeyPrefix.      * @param metadataProvider      *      A callback of type <code>ObjectMetadataProvider</code> which       *            is used to provide metadata for each file being uploaded.      */     public MultipleFileUpload uploadFileList(String bucketName, String virtualDirectoryKeyPrefix, File directory, List<File> files,ObjectMetadataProvider metadataProvider) {          if ( directory == null || !directory.exists() || !directory.isDirectory() ) {             throw new IllegalArgumentException("Must provide a common base directory for uploaded files");         }          if (virtualDirectoryKeyPrefix == null || virtualDirectoryKeyPrefix.length() == 0) {             virtualDirectoryKeyPrefix = "";         } else if ( !virtualDirectoryKeyPrefix.endsWith("/") ) {             virtualDirectoryKeyPrefix = virtualDirectoryKeyPrefix + "/";         }          TransferProgressImpl transferProgress = new TransferProgressImpl();         ProgressListener listener = new TransferProgressUpdatingListener(transferProgress);          List<UploadImpl> uploads = new LinkedList<UploadImpl>();         MultipleFileUploadImpl multipleFileUpload = new MultipleFileUploadImpl("Uploading etc", transferProgress, null, virtualDirectoryKeyPrefix, bucketName, uploads);         multipleFileUpload.setMonitor(new MultipleFileTransferMonitor(multipleFileUpload, uploads));          final AllDownloadsQueuedLock allTransfersQueuedLock = new AllDownloadsQueuedLock();         MultipleFileTransferStateChangeListener stateChangeListener = new MultipleFileTransferStateChangeListener(                 allTransfersQueuedLock, multipleFileUpload);          if ( files == null || files.isEmpty()) {             multipleFileUpload.setState(TransferState.Completed);         }          long totalSize = 0;         for (File f : files) {             //Check, if file, since only files can be uploaded.             if (f.isFile()) {                 totalSize += f.length();                 String key = f.getAbsolutePath().substring(directory.getAbsolutePath().length() + 1)                         .replaceAll("\\\\", "/");                                  ObjectMetadata metadata=new ObjectMetadata();                                  // Invoke the callback if it's present.                 // The callback allows the user to customize the metadata for each file being uploaded.                 if(metadataProvider!=null){                    metadataProvider.provideObjectMetadata(f,metadata);                 }                                  uploads.add((UploadImpl) upload(                         new PutObjectRequest(bucketName, virtualDirectoryKeyPrefix + key, f).withMetadata(metadata).withProgressListener(listener),                         stateChangeListener));             }         }          transferProgress.setTotalBytesToTransfer(totalSize);          // Notify all state changes waiting for the uploads to all be queued         // to wake up and continue         synchronized (allTransfersQueuedLock) {             allTransfersQueuedLock.allQueued = true;             allTransfersQueuedLock.notifyAll();         }          return multipleFileUpload;     }      /**      * Lists files in the directory given and adds them to the result list      * passed in, optionally adding subdirectories recursively.      */     private void listFiles(File dir, List<File> results, boolean includeSubDirectories) {         File[] found = dir.listFiles();         if ( found != null ) {             for ( File f : found ) {                 if (f.isDirectory()) {                     if (includeSubDirectories) {                         listFiles(f, results, includeSubDirectories);                     }                 } else {                     results.add(f);                 }             }         }     }      /**      * <p>      * Aborts any multipart uploads that were initiated before the specified date.      * </p>      * <p>      * This method is useful for cleaning up any interrupted multipart uploads.      * <code>TransferManager</code> attempts to abort any failed uploads,      * but in some cases this may not be possible, such as if network connectivity      * is completely lost.      * </p>      *      * @param bucketName      *            The name of the bucket containing the multipart uploads to      *            abort.      * @param date      *            The date indicating which multipart uploads should be aborted.      */     public void abortMultipartUploads(String bucketName, Date date)             throws AmazonServiceException, AmazonClientException {         MultipartUploadListing uploadListing = s3.listMultipartUploads(appendUserAgent(                 new ListMultipartUploadsRequest(bucketName), USER_AGENT));         do {             for (MultipartUpload upload : uploadListing.getMultipartUploads()) {                 if (upload.getInitiated().compareTo(date) < 0) {                     s3.abortMultipartUpload(appendUserAgent(new AbortMultipartUploadRequest(                             bucketName, upload.getKey(), upload.getUploadId()), USER_AGENT));                 }             }              ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName)                 .withUploadIdMarker(uploadListing.getNextUploadIdMarker())                 .withKeyMarker(uploadListing.getNextKeyMarker());             uploadListing = s3.listMultipartUploads(appendUserAgent(request, USER_AGENT));         } while (uploadListing.isTruncated());     }      /**      * Forcefully shuts down this TransferManager instance - currently executing      * transfers will not be allowed to finish. Callers should use this method      * when they either:      * <ul>      * <li>have already verified that their transfers have completed by checking      * each transfer's state      * <li>need to exit quickly and don't mind stopping transfers before they      * complete.      * </ul>      * <p>      * Callers should also remember that uploaded parts from an interrupted      * upload may not always be automatically cleaned up, but callers can use      * {@link #abortMultipartUploads(String, Date)} to clean up any upload      * parts.      */     public void shutdownNow() {         threadPool.shutdownNow();         timedThreadPool.shutdownNow();          if (s3 instanceof AmazonS3Client) {             ((AmazonS3Client)s3).shutdown();         }     }      public <X extends AmazonWebServiceRequest> X appendUserAgent(X request, String userAgent) {         request.getRequestClientOptions().addClientMarker(USER_AGENT);         return request;     }      private static final String USER_AGENT = TransferManager.class.getName() + "/" + VersionInfoUtils.getVersion();      private static final String DEFAULT_DELIMITER = "/";      /**      * There is no need for threads from timedThreadPool if there is no more running threads in current process,      * so we need a daemon thread factory for it.      */     private static final ThreadFactory daemonThreadFactory = new ThreadFactory() {         final AtomicInteger threadCount = new AtomicInteger( 0 );         public Thread newThread(Runnable r) {             int threadNumber = threadCount.incrementAndGet();             Thread thread = new Thread(r);             thread.setDaemon(true);             thread.setName("S3TransferManagerTimedThread-" + threadNumber);             return thread;         }     }; } " compose:StringConcatenation merge: LineBased]
